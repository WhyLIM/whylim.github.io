{
    "version": "https://jsonfeed.org/version/1",
    "title": "Being on sea, sail; being on land, settle. • All posts by \"openai api\" tag",
    "description": "",
    "home_page_url": "https://new.limina.top",
    "items": [
        {
            "id": "https://new.limina.top/2024/10/21/%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%92%8C%E8%A7%84%E8%8C%83%E5%8C%96/",
            "url": "https://new.limina.top/2024/10/21/%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%92%8C%E8%A7%84%E8%8C%83%E5%8C%96/",
            "title": "文献信息抽取和规范化",
            "date_published": "2024-10-21T06:22:01.000Z",
            "content_html": "<h1 id=\"文献信息抽取和规范化\"><a class=\"anchor\" href=\"#文献信息抽取和规范化\">#</a> 文献信息抽取和规范化</h1>\n<h2 id=\"过去的做法\"><a class=\"anchor\" href=\"#过去的做法\">#</a> 过去的做法</h2>\n<p>自我的科研生涯以来，已经参与构建和发布了多个生物标志物数据库。例如：</p>\n<ul>\n<li><a href=\"http://www.eyeseeworld.com/cbd/\">Colorectal Cancer Biomarker Database (CBD2)</a></li>\n<li><a href=\"http://www.eyeseeworld.com/aging/\">Aging Biomarker Compendium (ABC)</a></li>\n</ul>\n<p>以及正在做的 Alzheimer's Disease Biomarker Database (ADDB)</p>\n<p>在数据收集的开始，我们的标准流程是，讨论制定一个检索词（被称为 PubMed Search Query），然后使用这个检索词在 PubMed 中检索相关文献</p>\n<p>例如 Aging Biomarker Compendium (ABC) 的检索词为：</p>\n<pre><code>(((((biomarker [Title/Abstract]) OR marker [Title/Abstract]) OR indicator [Title/Abstract]) OR predictor [Title/Abstract])) AND “Aging”[Mesh] NOT (Review[Publication Type])\n</code></pre>\n<p>对于数据的筛选与提取，过去的做法其实非常难登大雅，就是对搜索到的文献全部进行人工阅读，然后提取出我们感兴趣的信息。</p>\n<p>例如，对于以上提到的数据库构建，提取的任务是获得生物标志物及其相关的信息。</p>\n<p>人工阅读的方法固然存在其优势，例如在大多数情况下，如果阅读者为此领域的专家，基本上可以保证信息的准确性。</p>\n<p>但也有极其明显的弊端，例如效率低下，人容易产生疲劳，以及容易产生主观偏差。此外，由人手动提取的信息往往缺乏规范性和一致性，这会导致后续的数据处理和分析变得困难。</p>\n<p>历史的第一篇工作是 <a href=\"https://academic.oup.com/database/article/doi/10.1093/database/bay046/5010523\">CBD: a biomarker database for colorectal cancer</a>，发表于 2018 年。这篇文章从 8753 篇文献开始，经过人工筛选，最终获得 1115 篇文献作为数据源，收集了 870 种不同的结直肠癌生物标志物。</p>\n<p>稍微做一个计算：一篇普通学术论文大约在 5000-8000 字，假设读者对领域熟悉、外语水平较高且带有一定的目的性，那么读者的阅读速度应该至少可以达到每分钟 300-400 字。排除掉付费、无法获得全文以及一眼可以看出无相关信息的文献，我们假设真正正常阅读的文献为一半，即 4400 篇左右。</p>\n<p>那么，4400 篇文献，需要阅读 4400 * 5000 / 400 = 55000 分钟，大约需要 916 小时，如果一天工作 12 小时，则大约需要 76 天。</p>\n<p>这项工作当年的人工阅读几乎由一人完成，耗费了大量时间。</p>\n<h2 id=\"方案的更新\"><a class=\"anchor\" href=\"#方案的更新\">#</a> 方案的更新</h2>\n<p>现在，我们有了新的工具，例如 <a href=\"https://www.ncbi.nlm.nih.gov/home/develop/api/\">NCBI API</a> 和 <a href=\"https://openai.com/api/\">OpenAI API</a>。</p>\n<p>在 <a href=\"https://new.limina.top/2024/07/01/%E4%BD%BF%E7%94%A8EntrezAPI%E8%BF%9B%E8%A1%8CPubMed%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/\">使用 Entrez API 进行 PubMed 文献信息提取</a> 中，我们已经介绍了如何使用 Entrez API 进行文献基础信息的提取，例如文献标题、摘要、关键词、作者、发表时间、DOI 等。</p>\n<p>但是当我们需要提取一些具体的信息，如生物标志物的名称、类型和其他信息时，NCBI 提供的 API 并不能完成这样的任务。</p>\n<p>近两年，OpenAI 训练的 GPT 模型已经取得了巨大的成功，<a href=\"https://chatgpt.com/\">ChatGPT</a> 已经可以完成很多复杂的任务，例如文本生成、文本摘要、文本分类、文本翻译等。</p>\n<p>因此，我们可以使用 GPT 模型来帮助我们完成文献信息的提取和规范化，以在保持信息准确性的同时，减轻人工阅读的负担，并提高数据收集的效率。</p>\n",
            "tags": [
                "OpenAI API",
                "GPT",
                "Text mining",
                "Entrze API"
            ]
        },
        {
            "id": "https://new.limina.top/2024/10/15/%E4%BD%BF%E7%94%A8%E7%BB%93%E6%9E%84%E5%8C%96%E8%BE%93%E5%87%BA%E8%A7%84%E8%8C%83%20OpenAI%20API%20%E7%9A%84%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C/",
            "url": "https://new.limina.top/2024/10/15/%E4%BD%BF%E7%94%A8%E7%BB%93%E6%9E%84%E5%8C%96%E8%BE%93%E5%87%BA%E8%A7%84%E8%8C%83%20OpenAI%20API%20%E7%9A%84%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C/",
            "title": "使用结构化输出规范 OpenAI API 的输出结果",
            "date_published": "2024-10-15T10:20:36.000Z",
            "content_html": "<h1 id=\"使用结构化输出规范-openai-api-的输出结果\"><a class=\"anchor\" href=\"#使用结构化输出规范-openai-api-的输出结果\">#</a> 使用结构化输出规范 OpenAI API 的输出结果</h1>\n<p>在 AI 驱动的应用程序中，生成结构化数据是一个核心需求。我们通常希望 AI 能够从非结构化的输入中提取信息，并将其转换为结构化数据格式以便后续的处理。随着 OpenAI API 的发展，** 结构化输出（Structured Outputs）** 特性已经被加入。</p>\n<h2 id=\"什么是结构化输出\"><a class=\"anchor\" href=\"#什么是结构化输出\">#</a> 什么是结构化输出？</h2>\n<p><strong>结构化输出</strong>是 OpenAI API 的一个新功能，允许我们通过提供 JSON Schema 来限制模型输出，使其完全符合预定义的数据结构。</p>\n<h2 id=\"实际应用生物标志物规范化\"><a class=\"anchor\" href=\"#实际应用生物标志物规范化\">#</a> 实际应用：生物标志物规范化</h2>\n<p>我们通过一个例子来展示如何使用结构化输出规范 OpenAI API 的输出结果。</p>\n<p>我有一个衰老相关的生物标志物表格，它们是从文献中手动提取的，由于提取比较粗糙，我只有它们的名称并且可能并不标准。现在我想借助 GPT 来规范化，同时生成新的两列 GPTAnno 和 Symbol，要求</p>\n<ol>\n<li>规范生物标志物的名称</li>\n<li>注释此生物标志物的功能</li>\n<li>如果生物标志物是明确的基因，给出基因 SYMBOL；如果是体内的化学物质 / 小分子，给出直接相关的基因 SYMBOL。多个 SYMBOL 用英文逗号加空格隔开。其他情况返回 “/”。</li>\n</ol>\n<h3 id=\"prompt-设计\"><a class=\"anchor\" href=\"#prompt-设计\">#</a> Prompt 设计</h3>\n<p>我们需要设计两部分：给模型的角色（role）以及提示词（prompt）</p>\n<p>例如，角色可以定义为</p>\n<figure class=\"highlight markdown\"><figcaption data-lang=\"markdown\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>You are a knowledgeable assistant specialized in aging-related biomarkers.</pre></td></tr></table></figure><p>提示词则需要更详细：</p>\n<figure class=\"highlight markdown\"><figcaption data-lang=\"markdown\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>I have a biomarker related to aging.</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token list punctuation\">1.</span> Please standardize the name of this biomarker if it's unclear, and provide a concise annotation describing its function in biological processes, especially related to aging.</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token list punctuation\">2.</span> If this biomarker represents specific gene(s), provide the official SYMBOL(s) for the gene(s). If it's a chemical substance or small molecule, provide the directly related gene SYMBOL(s). If no relevant gene is associated, return \"/\".</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token list punctuation\">3.</span> If there are multiple SYMBOLs, separate them with a comma followed by a space (\", \").</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>The output should be in JSON format with the following fields:</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\">\n{{\n  \"Biomarker_Std\": \"the standardized name of this biomarker\",\n  \"GPTAnno\": \"standardized biomarker name and its biological function\",\n  \"Symbol\": \"associated gene SYMBOL(s) or '/' if none\"\n}}\n</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>Here is the biomarker: '&#123;biomarker_name&#125;'</pre></td></tr></table></figure><h3 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 代码实现</h3>\n<p>我们使用 OpenAI 的结构化输出功能，通过定义自定义的 JSON Schema，确保模型返回的结果始终包含标准化后的生物标志物名称、注释以及相关的基因符号。以下是代码实现。</p>\n<h4 id=\"1-加载环境变量和设置代理\"><a class=\"anchor\" href=\"#1-加载环境变量和设置代理\">#</a> 1. 加载环境变量和设置代理</h4>\n<p>我们可以在工作目录创建一个  <code>.env</code>  文件，用于存储环境变量：</p>\n<figure class=\"highlight markdown\"><figcaption data-lang=\"markdown\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>MODEL=gpt-4o-mini</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>OPENAI_API_KEY=sk-xxxx</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>HTTP_PROXY=http://127.0.0.1:7890</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>HTTPS_PROXY=http://127.0.0.1:7890</pre></td></tr></table></figure><p>使用  <code>python-dotenv</code>  加载  <code>.env</code>  文件中的 API key、模型名称及代理设置。这样可以确保敏感信息不会硬编码在代码中，并且方便在不同的环境中部署。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 加载 .env 文件</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>load_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 设置代理（如果需要）</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">set_proxy</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    http_proxy <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HTTP_PROXY'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    https_proxy <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">'HTTPS_PROXY'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token keyword\">if</span> http_proxy<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'HTTP_PROXY'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> http_proxy</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token keyword\">if</span> https_proxy<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'HTTPS_PROXY'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> https_proxy</pre></td></tr></table></figure><h4 id=\"2-定义-schema\"><a class=\"anchor\" href=\"#2-定义-schema\">#</a> 2. 定义 Schema</h4>\n<p>为了确保 OpenAI API 的输出符合我们的需求，我们定义了一个  <code>BiomarkerAnnotation</code>  的数据结构。这个结构包含三部分： <code>Biomarker_Std</code> （标准化后的生物标志物名称）、 <code>GPTAnno</code> （注释）和  <code>Symbol</code> （基因符号）。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> pydantic <span class=\"token keyword\">import</span> BaseModel</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 定义生物标志物注释的 Schema</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">BiomarkerAnnotation</span><span class=\"token punctuation\">(</span>BaseModel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    Biomarker_Std<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span>  <span class=\"token comment\"># 标准化后的生物标志物名称</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    GPTAnno<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span>  <span class=\"token comment\"># 标准化后的名称及其生物功能注释</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    Symbol<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span>  <span class=\"token comment\"># 相关基因的 SYMBOL 或 \"/\"</span></pre></td></tr></table></figure><h4 id=\"3-生成规范化的注释\"><a class=\"anchor\" href=\"#3-生成规范化的注释\">#</a> 3. 生成规范化的注释</h4>\n<p><code>annotate_biomarker</code>  函数通过调用 OpenAI API，生成符合上述 Schema 的结构化输出。我们在函数中构建一个提示（prompt），要求模型规范化生物标志物名称，生成功能注释，并提供相关基因符号。使用 OpenAI 提供的  <code>completions.parse</code>  方法，可以保证输出与我们定义的 Schema 一致。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 初始化 OpenAI 客户端</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">init_openai_client</span><span class=\"token punctuation\">(</span>api_key<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">return</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 注释生物标志物函数</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">annotate_biomarker</span><span class=\"token punctuation\">(</span>biomarker_name<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> api_key<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> BiomarkerAnnotation<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    I have a biomarker related to aging.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    1. Please standardize the name of this biomarker if it's unclear, and provide a concise annotation describing its function in biological processes, especially related to aging.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    2. If this biomarker represents a specific gene, provide the official SYMBOL for the gene. If it's a chemical substance or small molecule, provide the directly related gene SYMBOL(s). If no relevant gene is associated, return \"/\".</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    3. If there are multiple SYMBOLs, separate them with a comma followed by a space (\", \").</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    The output should be in JSON format with the following fields:</pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    \n    {{\n      \"Biomarker_Std\": \"the standardized name of this biomarker\",\n      \"GPTAnno\": \"standardized biomarker name and its biological function\",\n      \"Symbol\": \"associated gene SYMBOL(s) or '/' if none\"\n    }}\n    </pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    Here is the biomarker: '</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>biomarker_name<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    \"\"\"</span></span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token comment\"># 使用 OpenAI 客户端请求</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    client <span class=\"token operator\">=</span> init_openai_client<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    completion <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>beta<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        model<span class=\"token operator\">=</span>model<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"You are a knowledgeable assistant specialized in aging-related biomarkers.\"</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> prompt<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        response_format<span class=\"token operator\">=</span>BiomarkerAnnotation<span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 使用自定义 Schema</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    <span class=\"token comment\"># 解析结果</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    message <span class=\"token operator\">=</span> completion<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>message</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>    <span class=\"token keyword\">if</span> message<span class=\"token punctuation\">.</span>parsed<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        <span class=\"token keyword\">return</span> message<span class=\"token punctuation\">.</span>parsed</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        <span class=\"token keyword\">return</span> message<span class=\"token punctuation\">.</span>refusal</pre></td></tr></table></figure><h4 id=\"4-处理批量生物标志物\"><a class=\"anchor\" href=\"#4-处理批量生物标志物\">#</a> 4. 处理批量生物标志物</h4>\n<p>我们需要处理多个生物标志物，并将结果保存为 CSV 文件。 <code>process_biomarkers</code>  函数从输入文件中读取生物标志物，然后调用  <code>annotate_biomarker</code>  函数生成结构化输出，并将结果存储在一个新的 CSV 文件中。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> time</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 批量处理生物标志物并保存结果</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">process_biomarkers</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> api_key<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> output_file<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    df_ans <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Biomarker'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Biomarker_Std'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'GPTAnno'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Symbol'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token keyword\">if</span> i <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token keyword\">and</span> i <span class=\"token operator\">%</span> <span class=\"token number\">50</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        p <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        biomarker <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Biomarker'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'正在处理第 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 个生物标志物，PMID 为：</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>p<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        response <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        <span class=\"token keyword\">for</span> attempt <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>            <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>                response <span class=\"token operator\">=</span> annotate_biomarker<span class=\"token punctuation\">(</span>biomarker<span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span>model<span class=\"token punctuation\">,</span> api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>                <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>            <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Error on attempt </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>attempt <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> for PMID </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>p<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>                time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">if</span> response <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Failed to process biomarker '</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>biomarker<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">' after 5 attempts.\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token comment\"># 保存结果</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        dfrow <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>            <span class=\"token string\">'PMID'</span><span class=\"token punctuation\">:</span> p<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>            <span class=\"token string\">'Biomarker'</span><span class=\"token punctuation\">:</span> biomarker<span class=\"token punctuation\">,</span>  </pre></td></tr><tr><td data-num=\"35\"></td><td><pre>            <span class=\"token string\">'Biomarker_Std'</span><span class=\"token punctuation\">:</span> response<span class=\"token punctuation\">.</span>Biomarker_Std<span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"36\"></td><td><pre>            <span class=\"token string\">'GPTAnno'</span><span class=\"token punctuation\">:</span> response<span class=\"token punctuation\">.</span>GPTAnno<span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"37\"></td><td><pre>            <span class=\"token string\">'Symbol'</span><span class=\"token punctuation\">:</span> response<span class=\"token punctuation\">.</span>Symbol</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        df_ans <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>df_ans<span class=\"token punctuation\">,</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>dfrow<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> ignore_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Processed: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>response<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\\n\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">500</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>            df_ans<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'intermediate_result_</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">.csv'</span></span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>    df_ans<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>output_file<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"All biomarkers processed and saved to </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>output_file<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "Structured Outputs",
                "OpenAI API",
                "GPT"
            ]
        }
    ]
}