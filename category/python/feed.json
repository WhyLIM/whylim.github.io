{
    "version": "https://jsonfeed.org/version/1",
    "title": "Being on sea, sail; being on land, settle. • All posts by \"python\" category",
    "description": "",
    "home_page_url": "https://whylim.github.io",
    "items": [
        {
            "id": "https://whylim.github.io/2024/07/01/%E4%BD%BF%E7%94%A8EntrezAPI%E8%BF%9B%E8%A1%8CPubMed%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/",
            "url": "https://whylim.github.io/2024/07/01/%E4%BD%BF%E7%94%A8EntrezAPI%E8%BF%9B%E8%A1%8CPubMed%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/",
            "title": "使用 Entrez API 进行 PubMed 文献信息提取",
            "date_published": "2024-06-30T18:58:06.000Z",
            "content_html": "<h1 id=\"使用-entrez-api-进行-pubmed-文献信息提取\"><a class=\"anchor\" href=\"#使用-entrez-api-进行-pubmed-文献信息提取\">#</a> 使用 Entrez API 进行 PubMed 文献信息提取</h1>\n<blockquote>\n<p>本文通过 Entrez API 从 PubMed 数据库中获取相关文献信息，并将这些信息保存到 CSV 文件中。在代码中，还处理了一些常见的网络异常和请求频率限制问题。</p>\n</blockquote>\n<h2 id=\"设置账户\"><a class=\"anchor\" href=\"#设置账户\">#</a> 设置账户</h2>\n<p>Biopython 使用 NCBI 官方提供的 Entrez API 进行数据检索。首先，我们需要在 NCBI 网站上注册一个账户。</p>\n<p>导入必要的库并设置 Entrez API 的电子邮件参数。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> Bio <span class=\"token keyword\">import</span> Entrez<span class=\"token punctuation\">,</span> Medline</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> time</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> urllib<span class=\"token punctuation\">.</span>error <span class=\"token keyword\">import</span> HTTPError</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>Entrez<span class=\"token punctuation\">.</span>email <span class=\"token operator\">=</span> <span class=\"token string\">\"xxx@xxx.xxx\"</span></pre></td></tr></table></figure><h2 id=\"检索词和文件名列表\"><a class=\"anchor\" href=\"#检索词和文件名列表\">#</a> 检索词和文件名列表</h2>\n<p>定义检索词列表和对应的 CSV 文件名列表，并设置提取日期需要用到的正则表达式。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>term_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token triple-quoted-string string\">'''检索词'''</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>fname_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'./test.csv'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 多个检索词分别保存为多个文件</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># term_list = ['''\"检索词 1''', '''\" 检索词 2''', '''\"检索词 3\"''', '''\"检索词 4\"''', '''\"检索词 5\"''']</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># fname_list = ['file1.csv', 'file2.csv', 'file3.csv', 'file4.csv', 'file5.csv']</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># 提取日期的正则表达式模式</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>date_pattern <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token string\">r'\\b\\d&#123;4&#125; \\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\b \\d&#123;1,2&#125;'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h2 id=\"处理检索词\"><a class=\"anchor\" href=\"#处理检索词\">#</a> 处理检索词</h2>\n<p>代码依次处理每个检索词，首先获取检索到的文献数量。</p>\n<p>由于 Entrez API 最多只能获取检索到的前 9999 篇（其实在网页上也是如此），若使用检索词检索到的文章数量少于 10,000 篇，则直接获取文献 ID 列表；</p>\n<p>否则，按年份分段进行检索以确保总数不超过 API 限制。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>num <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">for</span> term <span class=\"token keyword\">in</span> term_list<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db <span class=\"token operator\">=</span> <span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term <span class=\"token operator\">=</span> term<span class=\"token punctuation\">,</span> retmax <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    retmax <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"Count\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token comment\"># Entrez API 最多只能获取检索到的前 9999 篇</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token keyword\">if</span> retmax <span class=\"token operator\">&lt;</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db <span class=\"token operator\">=</span> <span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term <span class=\"token operator\">=</span> term<span class=\"token punctuation\">,</span> retmax <span class=\"token operator\">=</span> retmax<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"IdList\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        start_year <span class=\"token operator\">=</span> <span class=\"token number\">2004</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        end_year <span class=\"token operator\">=</span> <span class=\"token number\">2024</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        term_sublist <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token keyword\">for</span> year <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>start_year<span class=\"token punctuation\">,</span> end_year <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            query <span class=\"token operator\">=</span> term <span class=\"token operator\">+</span> <span class=\"token string-interpolation\"><span class=\"token string\">f' AND ((\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>year<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"[Date - Publication] : \"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>year<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"[Date - Publication]))'</span></span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>            term_sublist<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">for</span> subterm <span class=\"token keyword\">in</span> term_sublist<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db <span class=\"token operator\">=</span> <span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term <span class=\"token operator\">=</span> subterm<span class=\"token punctuation\">,</span> retmax <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>            handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>            retmax <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"Count\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>            handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db <span class=\"token operator\">=</span> <span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term <span class=\"token operator\">=</span> subterm<span class=\"token punctuation\">,</span> retmax <span class=\"token operator\">=</span> retmax<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>            record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>            handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>            pmid_list <span class=\"token operator\">+=</span> record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"IdList\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        <span class=\"token comment\"># 去重并降序    </span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> <span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> key <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> reverse <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h4 id=\"获取文献详细信息\"><a class=\"anchor\" href=\"#获取文献详细信息\">#</a> 获取文献详细信息</h4>\n<p>为了获取文献的详细信息，分批次（每次 50 篇）使用 Entrez.efetch 函数。</p>\n<p>考虑到网络异常和请求频率限制，添加了异常处理逻辑。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>            <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                handle_efetch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>efetch<span class=\"token punctuation\">(</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span> <span class=\"token operator\">=</span> pmid_list<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">:</span>i<span class=\"token operator\">+</span><span class=\"token number\">50</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> rettype <span class=\"token operator\">=</span> <span class=\"token string\">'medline'</span><span class=\"token punctuation\">,</span> retmode <span class=\"token operator\">=</span> <span class=\"token string\">\"text\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                records_efetch <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>Medline<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>handle_efetch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                handle_efetch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>                <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>            <span class=\"token keyword\">except</span> HTTPError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>                <span class=\"token keyword\">if</span> e<span class=\"token punctuation\">.</span>code <span class=\"token operator\">==</span> <span class=\"token number\">429</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 请求过于频繁</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>                    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>                    <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>                    <span class=\"token keyword\">raise</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>            <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>                <span class=\"token comment\"># 处理其他异常</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Error: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>                time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token keyword\">for</span> record_efetch <span class=\"token keyword\">in</span> records_efetch<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>            PMID <span class=\"token operator\">=</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>            <span class=\"token comment\"># 提取被引用信息和参考文献信息</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>            handle_elink <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>elink<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span><span class=\"token operator\">=</span>PMID<span class=\"token punctuation\">,</span> linkname<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed_pubmed_citedin,pubmed_pubmed_refs\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>            record_elink <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_elink<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            handle_elink<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>            linked <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>            references <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>            <span class=\"token keyword\">if</span> record_elink <span class=\"token keyword\">and</span> <span class=\"token string\">\"LinkSetDb\"</span> <span class=\"token keyword\">in</span> record_elink<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>                <span class=\"token keyword\">for</span> linkset <span class=\"token keyword\">in</span> record_elink<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkSetDb\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>                    <span class=\"token keyword\">if</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkName\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"pubmed_pubmed_citedin\"</span> <span class=\"token keyword\">and</span> <span class=\"token string\">\"Link\"</span> <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>                        linked<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">\"Id\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"Link\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>                    <span class=\"token keyword\">elif</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkName\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"pubmed_pubmed_refs\"</span> <span class=\"token keyword\">and</span> <span class=\"token string\">\"Link\"</span> <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>                        references<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">\"Id\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"Link\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>            <span class=\"token comment\"># 提取正式发表日期</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>            publication_date <span class=\"token operator\">=</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'SO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>            <span class=\"token keyword\">match</span> <span class=\"token operator\">=</span> date_pattern<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>publication_date<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>            formatted_publication_date <span class=\"token operator\">=</span> <span class=\"token keyword\">match</span><span class=\"token punctuation\">.</span>group<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> <span class=\"token keyword\">match</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>            record_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>                <span class=\"token string\">'Title'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'TI'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>                <span class=\"token string\">'Status'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'STAT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>                <span class=\"token string\">'Last Revision Date'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>                <span class=\"token string\">'ISSN'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'IS'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>                <span class=\"token string\">'Type'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>                <span class=\"token string\">'Year of Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'DP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token string\">'DP'</span> <span class=\"token keyword\">in</span> record_efetch <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>                <span class=\"token string\">'Date of Electronic Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'DEP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>                <span class=\"token string\">'Publication Date'</span><span class=\"token punctuation\">:</span> formatted_publication_date<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>                <span class=\"token string\">'Place of Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PL'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>                <span class=\"token string\">'F_Author'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'FAU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>                <span class=\"token string\">'Author'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>                <span class=\"token string\">'Affiliation'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AD'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>                <span class=\"token string\">'Abstract'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AB'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>                <span class=\"token string\">'Language'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LA'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>                <span class=\"token string\">'Keywords'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'OT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>                <span class=\"token string\">'PMID'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>                <span class=\"token string\">'Medline Volume'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'VI'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>                <span class=\"token string\">'Medline Issue'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'IP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>                <span class=\"token string\">'Medline Pagination'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PG'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>                <span class=\"token string\">'DOI'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token string\">'LID'</span> <span class=\"token keyword\">in</span> record_efetch <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>                <span class=\"token string\">'PMC'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMC'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>                <span class=\"token string\">'Processing History'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PSTT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>                <span class=\"token string\">'Publication Status'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PST'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>                <span class=\"token string\">'Journal Title Abbreviation'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'TA'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>                <span class=\"token string\">'Journal Title'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'JT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>                <span class=\"token string\">'Journal ID'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'JID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>                <span class=\"token string\">'Source'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'SO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>                <span class=\"token string\">'Grant List'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'GR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>                <span class=\"token string\">'cited'</span> <span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>linked<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>                <span class=\"token string\">'cited_by'</span><span class=\"token punctuation\">:</span> linked<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>                <span class=\"token string\">'References'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>references<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>                <span class=\"token string\">'References_PMID'</span><span class=\"token punctuation\">:</span> references<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>            <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>            data<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>record_dict<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'已成功获取 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 篇文献信息'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"82\"></td><td><pre>            df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>            fname <span class=\"token operator\">=</span> fname_list<span class=\"token punctuation\">[</span>num<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>            df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>fname<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>    num <span class=\"token operator\">+=</span> <span class=\"token number\">1</span></pre></td></tr></table></figure><h2 id=\"参考\"><a class=\"anchor\" href=\"#参考\">#</a> 参考</h2>\n<ul>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/books/NBK25501/\">Entrez Programming Utilities Help</a></li>\n<li><a href=\"https://whylim.github.io/E-utilities_zh-CN/\">我的汉化文档</a></li>\n</ul>\n",
            "tags": [
                "Python",
                "Entrez API",
                "NCBI"
            ]
        },
        {
            "id": "https://whylim.github.io/2020/11/01/jupyternotebook%E5%8C%85%E5%AF%BC%E5%85%A5%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/",
            "url": "https://whylim.github.io/2020/11/01/jupyternotebook%E5%8C%85%E5%AF%BC%E5%85%A5%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/",
            "title": "jupyter notebook 包导入路径问题",
            "date_published": "2020-11-01T02:04:00.000Z",
            "content_html": "<blockquote>\n<p>之前在 windows 下自己写的 python 包只要放到  <code>.../anaconda3/lib/pythonx.x/site-packages</code>  下就能导入了，到 ubuntu 里发现不行，因为由于各种奇奇怪怪的原因电脑上装了两个 jupyter notebook… 而且路径都不对</p>\n<p>感谢 CSDN 的大哥，让我用上了更简单的 Ubuntu</p>\n<p>参考：<a href=\"https://blog.csdn.net/qq%5C_34650787/article/details/83304080\">https://blog.csdn.net/qq\\_34650787/article/details/83304080</a></p>\n</blockquote>\n<p>先去两个 jupyter notebook 里 import 一个包  <code>sys</code></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>sys<span class=\"token punctuation\">.</span>executable</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 一个返回 '/usr/bin/python3'   这个是 anaconda 自带的 jupyter</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># 一个返回 '/snap/jupyter/6/bin/python'   这是我后来重装的 jupyter</span></pre></td></tr></table></figure><p>可能 anaconda 没装好</p>\n<p>终端输入 python3</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>limin@limin-Lenovo-XiaoXin-Air-15IKBR:~$ python3</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Python <span class=\"token number\">3.8</span>.5 <span class=\"token punctuation\">(</span>default, Jul <span class=\"token number\">28</span> <span class=\"token number\">2020</span>, <span class=\"token number\">12</span>:59:40<span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>GCC <span class=\"token number\">9.3</span>.0<span class=\"token punctuation\">]</span> on linux</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Type <span class=\"token string\">\"help\"</span>, <span class=\"token string\">\"copyright\"</span>, <span class=\"token string\">\"credits\"</span> or <span class=\"token string\">\"license\"</span> <span class=\"token keyword\">for</span> <span class=\"token function\">more</span> information.</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span></pre></td></tr></table></figure><p>没有 anaconda</p>\n<p>去添加一下环境变量</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>gedit ~/.bashrc</pre></td></tr></table></figure><p>在最后一行加入</p>\n<pre><code>export PATH=$PATH:/home/limin/anaconda3/bin\n</code></pre>\n<p>回到 shell，source 一下</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">source</span> ~/.bashrc</pre></td></tr></table></figure><p>再输入 python3（ubuntu20.04 内置了 python3，所以输 python 也行）</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>limin@limin-Lenovo-XiaoXin-Air-15IKBR:~$ python</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Python <span class=\"token number\">3.8</span>.3 <span class=\"token punctuation\">(</span>default, Jul  <span class=\"token number\">2</span> <span class=\"token number\">2020</span>, <span class=\"token number\">16</span>:21:59<span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>GCC <span class=\"token number\">7.3</span>.0<span class=\"token punctuation\">]</span> :: Anaconda, Inc. on linux</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Type <span class=\"token string\">\"help\"</span>, <span class=\"token string\">\"copyright\"</span>, <span class=\"token string\">\"credits\"</span> or <span class=\"token string\">\"license\"</span> <span class=\"token keyword\">for</span> <span class=\"token function\">more</span> information.</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span></pre></td></tr></table></figure><p>anaconda 出来了</p>\n<p>import 一下  <code>sys</code></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>sys<span class=\"token punctuation\">.</span>executable</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 返回 '/home/limin/anaconda3/bin/python'</span></pre></td></tr></table></figure><p>去 jupyter notebook 里 import</p>\n<p>第一个返回  <code>'/home/limin/anaconda3/bin/python'</code></p>\n<p>第二个仍然返回  <code>'/snap/jupyter/6/bin/python'</code></p>\n<p>所以用第一个</p>\n<p>把写的包放到  <code>/home/limin/anaconda3/lib/python3.8/site-packages</code></p>\n<p>再 import 就没问题了</p>\n<h2 id=\"后续新问题\"><a class=\"anchor\" href=\"#后续新问题\">#</a> 后续新问题</h2>\n<p>没有在 conda 环境里进入 jupyter 的话，路径就是自带 python 的包路径了</p>\n<p>conda activate 再 jupyter notebook 就行</p>\n",
            "tags": [
                "Python"
            ]
        }
    ]
}