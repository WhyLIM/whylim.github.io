{
    "version": "https://jsonfeed.org/version/1",
    "title": "Being on sea, sail; being on land, settle. • All posts by \"python\" category",
    "description": "",
    "home_page_url": "https://new.limina.top",
    "items": [
        {
            "id": "https://new.limina.top/2024/07/03/%E4%BD%BF%E7%94%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%B3%95%E8%AF%86%E5%88%AB%E7%96%BE%E7%97%85%E6%A8%A1%E5%9D%97/",
            "url": "https://new.limina.top/2024/07/03/%E4%BD%BF%E7%94%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%B3%95%E8%AF%86%E5%88%AB%E7%96%BE%E7%97%85%E6%A8%A1%E5%9D%97/",
            "title": "使用网络方法识别疾病模块",
            "date_published": "2024-07-03T10:11:59.000Z",
            "content_html": "<h1 id=\"使用网络方法识别疾病模块\"><a class=\"anchor\" href=\"#使用网络方法识别疾病模块\">#</a> 使用网络方法识别疾病模块</h1>\n<blockquote>\n<p>在 2015 年的一篇 Science <a href=\"https://www.science.org/doi/full/10.1126/science.1257601\">&quot;Uncovering disease-disease relationships through the incomplete interactome&quot;</a> 中，作者提出了一种基于网络距离的方法来识别和分析疾病模块，并揭示疾病之间的关系。</p>\n</blockquote>\n<p><img loading=\"lazy\" data-src=\"https://img.limina.top/blog/image-20240703181243724.png\" alt=\"image-20240703181243724\" /></p>\n<h2 id=\"背景\"><a class=\"anchor\" href=\"#背景\">#</a> 背景</h2>\n<p>疾病不是由单个基因异常直接导致的，而是由多个分子过程的相互作用所引起的。这些过程之间的关系被编码在相互作用网络（interactome）中，这个网络集成了细胞内所有的物理相互作用，包括蛋白质 - 蛋白质、调控蛋白质 - DNA 和代谢相互作用。</p>\n<p>研究表明，疾病相关的蛋白质往往聚集在相互作用网络的同一邻域内，形成一个疾病模块。</p>\n<p>研究显示只有当与疾病相关的基因数量超过某个临界值时，我们才能揭示疾病模块。研究发现，与 226 种疾病相关的蛋白质在同一网络邻域内聚集，表现出显著的形成可识别疾病模块的趋势。疾病蛋白质在网络中的聚集程度越高，相应基因的生物学和功能相似性越高。</p>\n<h2 id=\"方法\"><a class=\"anchor\" href=\"#方法\">#</a> 方法</h2>\n<p>文章的补充文件中提供了两个 Python 脚本：</p>\n<h3 id=\"separationpy\"><a class=\"anchor\" href=\"#separationpy\">#</a> <a href=\"http://separation.py\">separation.py</a></h3>\n<p>这个脚本用于计算基于网络的距离 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{AB}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">A</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和分离度 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{AB}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">A</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ，用以表示两个给定基因集 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 在给定网络上的相对位置和分离度。</p>\n<h3 id=\"localizationpy\"><a class=\"anchor\" href=\"#localizationpy\">#</a> <a href=\"http://localization.py\">localization.py</a></h3>\n<p>此脚本的主要功能是计算一个给定基因集在相互作用网络中的本地化特性。它会计算以下 3 个指标：</p>\n<ol>\n<li><strong>最大连通子图的大小 (S)</strong>：给定基因集在相互作用网络中形成的最大连通子图（LCC）的大小。</li>\n<li><strong>平均最短路径长度 (d_s)</strong>：基因集内所有基因对之间的平均最短路径长度。</li>\n<li><strong>随机期望值</strong>：通过随机模拟生成相同数量的基因集，并计算这些随机基因集的最大连通子图大小的期望值和标准差，然后比较实际基因集的结果，输出 z-score。</li>\n</ol>\n<p>然而，给出的代码都是基于 Python2 语法的，现在主流的 Python 版本是 Python3，所以我用 Python3 的语法重写了这两个脚本。</p>\n<h2 id=\"重写后的代码\"><a class=\"anchor\" href=\"#重写后的代码\">#</a> 重写后的代码</h2>\n<h3 id=\"separation_py3py\"><a class=\"anchor\" href=\"#separation_py3py\">#</a> separation_py3.py</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#! /usr/bin/env python3</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"4\"></td><td><pre># -----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"6\"></td><td><pre># separation_py3.py</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"8\"></td><td><pre># by Joerg Menche</pre></td></tr><tr><td data-num=\"9\"></td><td><pre># Last Modified: 2014-12-06</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"11\"></td><td><pre># This code determines the network-based distance and separation for</pre></td></tr><tr><td data-num=\"12\"></td><td><pre># two given sets of nodes on a given network as described in </pre></td></tr><tr><td data-num=\"13\"></td><td><pre># </pre></td></tr><tr><td data-num=\"14\"></td><td><pre># Uncovering Disease-Disease Relationships Through The Human</pre></td></tr><tr><td data-num=\"15\"></td><td><pre># Interactome</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"17\"></td><td><pre># by Joerg Menche, Amitabh Sharma, Maksim Kitsak, Susan Dina</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>#    Ghiassian, Marc Vidal, Joseph Loscalzo &amp; Albert-Laszlo Barabasi</pre></td></tr><tr><td data-num=\"19\"></td><td><pre># </pre></td></tr><tr><td data-num=\"20\"></td><td><pre># -----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"21\"></td><td><pre># </pre></td></tr><tr><td data-num=\"22\"></td><td><pre># This program will calculate the network-based distance d_AB and</pre></td></tr><tr><td data-num=\"23\"></td><td><pre># separation s_AB between two gene sets A and B.</pre></td></tr><tr><td data-num=\"24\"></td><td><pre># </pre></td></tr><tr><td data-num=\"25\"></td><td><pre># * Required input:</pre></td></tr><tr><td data-num=\"26\"></td><td><pre># </pre></td></tr><tr><td data-num=\"27\"></td><td><pre>#   two files containing the gene sets A and B. The file must be in</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>#   form of a table, one gene per line. If the table contains several</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>#   columns, they must be tab-separated, only the first column will be</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>#   used. See the two files MS.txt and PD.txt for valid examples (they</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>#   contain genes for multiple sclerosis and peroxisomal disorders,</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>#   respectively).</pre></td></tr><tr><td data-num=\"33\"></td><td><pre># </pre></td></tr><tr><td data-num=\"34\"></td><td><pre># * Optional input:  </pre></td></tr><tr><td data-num=\"35\"></td><td><pre># </pre></td></tr><tr><td data-num=\"36\"></td><td><pre>#   - file containing an interaction network. If no file is given, the</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>#     default network \"interactome.tsv\" will be used instead. The file</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>#     must contain an edgelist provided as a tab-separated table. The</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>#     first two columns of the table will be interpreted as an</pre></td></tr><tr><td data-num=\"40\"></td><td><pre>#     interaction gene1 &lt;==> gene2</pre></td></tr><tr><td data-num=\"41\"></td><td><pre># </pre></td></tr><tr><td data-num=\"42\"></td><td><pre>#  - filename for the output. If none is given,</pre></td></tr><tr><td data-num=\"43\"></td><td><pre>#    \"separation_results.txt\" will be used</pre></td></tr><tr><td data-num=\"44\"></td><td><pre>#  </pre></td></tr><tr><td data-num=\"45\"></td><td><pre># </pre></td></tr><tr><td data-num=\"46\"></td><td><pre># Here's an example that should work, provided the files are in the same</pre></td></tr><tr><td data-num=\"47\"></td><td><pre># directory as this python script:</pre></td></tr><tr><td data-num=\"48\"></td><td><pre># </pre></td></tr><tr><td data-num=\"49\"></td><td><pre># ./separation_py3.py -n interactome.tsv --g1 MS.txt --g2 PD.txt -o output.txt</pre></td></tr><tr><td data-num=\"50\"></td><td><pre># </pre></td></tr><tr><td data-num=\"51\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"52\"></td><td><pre># -----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"53\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre></pre></td></tr><tr><td data-num=\"55\"></td><td><pre><span class=\"token keyword\">import</span> networkx <span class=\"token keyword\">as</span> nx</pre></td></tr><tr><td data-num=\"56\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"57\"></td><td><pre><span class=\"token keyword\">import</span> argparse</pre></td></tr><tr><td data-num=\"58\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"59\"></td><td><pre></pre></td></tr><tr><td data-num=\"60\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"61\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"62\"></td><td><pre></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>           S T A R T   D E F I N I T I O N S </pre></td></tr><tr><td data-num=\"64\"></td><td><pre></pre></td></tr><tr><td data-num=\"65\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"66\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre></pre></td></tr><tr><td data-num=\"68\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">print_usage</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"70\"></td><td><pre>    打印使用说明</pre></td></tr><tr><td data-num=\"71\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>    usage_message <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"73\"></td><td><pre># ----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"74\"></td><td><pre></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>This program will calculate the network-based distance d_AB and</pre></td></tr><tr><td data-num=\"76\"></td><td><pre>separation s_AB between two gene sets A and B.</pre></td></tr><tr><td data-num=\"77\"></td><td><pre></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>* Required input:</pre></td></tr><tr><td data-num=\"79\"></td><td><pre></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>  two files containing the gene sets A and B. The file must be in form</pre></td></tr><tr><td data-num=\"81\"></td><td><pre>  of a table, one gene per line. If the table contains several</pre></td></tr><tr><td data-num=\"82\"></td><td><pre>  columns, they must be tab-separated, only the first column will be</pre></td></tr><tr><td data-num=\"83\"></td><td><pre>  used. See the two files MS.txt and PD.txt for valid examples (they</pre></td></tr><tr><td data-num=\"84\"></td><td><pre>  contain genes for multiple sclerosis and peroxisomal disorders,</pre></td></tr><tr><td data-num=\"85\"></td><td><pre>  respectively).</pre></td></tr><tr><td data-num=\"86\"></td><td><pre></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>* Optional input:  </pre></td></tr><tr><td data-num=\"88\"></td><td><pre></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>  - file containing an interaction network. If no file is given, the</pre></td></tr><tr><td data-num=\"90\"></td><td><pre>    default network \\\"interactome.tsv\\\" will be used instead. The file</pre></td></tr><tr><td data-num=\"91\"></td><td><pre>    must contain an edgelist provided as a tab-separated table. The</pre></td></tr><tr><td data-num=\"92\"></td><td><pre>    first two columns of the table will be interpreted as an</pre></td></tr><tr><td data-num=\"93\"></td><td><pre>    interaction gene1 &lt;==> gene2</pre></td></tr><tr><td data-num=\"94\"></td><td><pre></pre></td></tr><tr><td data-num=\"95\"></td><td><pre> - filename for the output. If none is given,</pre></td></tr><tr><td data-num=\"96\"></td><td><pre>   \\\"separation_results.txt\\\" will be used</pre></td></tr><tr><td data-num=\"97\"></td><td><pre> </pre></td></tr><tr><td data-num=\"98\"></td><td><pre></pre></td></tr><tr><td data-num=\"99\"></td><td><pre>Here's an example that should work, provided the files are in the same</pre></td></tr><tr><td data-num=\"100\"></td><td><pre>directory as this python script:</pre></td></tr><tr><td data-num=\"101\"></td><td><pre></pre></td></tr><tr><td data-num=\"102\"></td><td><pre>./separation_py3.py -n interactome.tsv --g1 MS.txt --g2 PD.txt -o output.txt</pre></td></tr><tr><td data-num=\"103\"></td><td><pre></pre></td></tr><tr><td data-num=\"104\"></td><td><pre># ----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"105\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"106\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>usage_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>    sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"109\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">read_network</span><span class=\"token punctuation\">(</span>network_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"110\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"111\"></td><td><pre>    读取网络文件并构建图</pre></td></tr><tr><td data-num=\"112\"></td><td><pre></pre></td></tr><tr><td data-num=\"113\"></td><td><pre>    * 边列表必须是制表符分隔的表。表的前两列将被解释为</pre></td></tr><tr><td data-num=\"114\"></td><td><pre>      相互作用 gene1 &lt;==> gene2</pre></td></tr><tr><td data-num=\"115\"></td><td><pre></pre></td></tr><tr><td data-num=\"116\"></td><td><pre>    * 以 '#' 开头的行将被忽略</pre></td></tr><tr><td data-num=\"117\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"118\"></td><td><pre>    G <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>Graph<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>network_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>        <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre>            <span class=\"token comment\"># 忽略以 '#' 开头的行</span></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>            <span class=\"token keyword\">if</span> line<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"123\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"124\"></td><td><pre>            <span class=\"token comment\"># 解析行中的前两列作为交互节点</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>            node1<span class=\"token punctuation\">,</span> node2 <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'\\t'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"126\"></td><td><pre>            G<span class=\"token punctuation\">.</span>add_edge<span class=\"token punctuation\">(</span>node1<span class=\"token punctuation\">,</span> node2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"127\"></td><td><pre></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n> done loading network:\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"129\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> network contains &#123;&#125; nodes and &#123;&#125; links\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>number_of_nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> G<span class=\"token punctuation\">.</span>number_of_edges<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"130\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"131\"></td><td><pre>    <span class=\"token keyword\">return</span> G</pre></td></tr><tr><td data-num=\"132\"></td><td><pre></pre></td></tr><tr><td data-num=\"133\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">read_gene_list</span><span class=\"token punctuation\">(</span>gene_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"135\"></td><td><pre>    从外部文件读取基因列表。</pre></td></tr><tr><td data-num=\"136\"></td><td><pre></pre></td></tr><tr><td data-num=\"137\"></td><td><pre>    * 基因必须作为表提供。如果表有多列，则它们必须是</pre></td></tr><tr><td data-num=\"138\"></td><td><pre>      制表符分隔。只使用第一列。</pre></td></tr><tr><td data-num=\"139\"></td><td><pre></pre></td></tr><tr><td data-num=\"140\"></td><td><pre>    * 以 '#' 开头的行将被忽略</pre></td></tr><tr><td data-num=\"141\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"142\"></td><td><pre>    genes_set <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"143\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>gene_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"144\"></td><td><pre>        <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"145\"></td><td><pre>            <span class=\"token keyword\">if</span> line<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"146\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"147\"></td><td><pre>            gene <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'\\t'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"148\"></td><td><pre>            genes_set<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>gene<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"149\"></td><td><pre></pre></td></tr><tr><td data-num=\"150\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n> done reading genes:\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> &#123;&#125; genes found in &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> gene_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"152\"></td><td><pre></pre></td></tr><tr><td data-num=\"153\"></td><td><pre>    <span class=\"token keyword\">return</span> genes_set</pre></td></tr><tr><td data-num=\"154\"></td><td><pre></pre></td></tr><tr><td data-num=\"155\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">remove_self_links</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"156\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"157\"></td><td><pre>    移除图中的自环边</pre></td></tr><tr><td data-num=\"158\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"159\"></td><td><pre>    sl <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>nx<span class=\"token punctuation\">.</span>selfloop_edges<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"160\"></td><td><pre>    G<span class=\"token punctuation\">.</span>remove_edges_from<span class=\"token punctuation\">(</span>sl<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"161\"></td><td><pre></pre></td></tr><tr><td data-num=\"162\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_pathlengths_for_single_set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> given_gene_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"163\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"164\"></td><td><pre>    计算给定基因集合中各基因对之间的最短路径长度。</pre></td></tr><tr><td data-num=\"165\"></td><td><pre>    结果存储在字典中：</pre></td></tr><tr><td data-num=\"166\"></td><td><pre>    all_path_lengths[gene1][gene2] = l</pre></td></tr><tr><td data-num=\"167\"></td><td><pre>    其中 gene1 &lt; gene2，因此每对只存储一次</pre></td></tr><tr><td data-num=\"168\"></td><td><pre></pre></td></tr><tr><td data-num=\"169\"></td><td><pre>    参数：</pre></td></tr><tr><td data-num=\"170\"></td><td><pre>    - G: 网络</pre></td></tr><tr><td data-num=\"171\"></td><td><pre>    - gene_set: 要计算路径的基因集</pre></td></tr><tr><td data-num=\"172\"></td><td><pre></pre></td></tr><tr><td data-num=\"173\"></td><td><pre>    返回：</pre></td></tr><tr><td data-num=\"174\"></td><td><pre>    - all_path_lengths[gene1][gene2] = l</pre></td></tr><tr><td data-num=\"175\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"176\"></td><td><pre></pre></td></tr><tr><td data-num=\"177\"></td><td><pre>    <span class=\"token comment\"># 去除不在网络中的节点</span></pre></td></tr><tr><td data-num=\"178\"></td><td><pre>    all_genes_in_network <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"179\"></td><td><pre>    gene_set <span class=\"token operator\">=</span> given_gene_set <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"180\"></td><td><pre></pre></td></tr><tr><td data-num=\"181\"></td><td><pre>    all_path_lengths <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"182\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"183\"></td><td><pre>    <span class=\"token comment\"># 计算所有可能对的距离</span></pre></td></tr><tr><td data-num=\"184\"></td><td><pre>    <span class=\"token keyword\">for</span> gene1 <span class=\"token keyword\">in</span> gene_set<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"185\"></td><td><pre>        <span class=\"token keyword\">if</span> gene1 <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> all_path_lengths<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"186\"></td><td><pre>            all_path_lengths<span class=\"token punctuation\">[</span>gene1<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"187\"></td><td><pre>        <span class=\"token keyword\">for</span> gene2 <span class=\"token keyword\">in</span> gene_set<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"188\"></td><td><pre>            <span class=\"token keyword\">if</span> gene1 <span class=\"token operator\">&lt;</span> gene2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"189\"></td><td><pre>                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"190\"></td><td><pre>                    l <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>shortest_path_length<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> source<span class=\"token operator\">=</span>gene1<span class=\"token punctuation\">,</span> target<span class=\"token operator\">=</span>gene2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"191\"></td><td><pre>                    all_path_lengths<span class=\"token punctuation\">[</span>gene1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>gene2<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> l</pre></td></tr><tr><td data-num=\"192\"></td><td><pre>                <span class=\"token keyword\">except</span> nx<span class=\"token punctuation\">.</span>NetworkXNoPath<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"193\"></td><td><pre>                    <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"194\"></td><td><pre></pre></td></tr><tr><td data-num=\"195\"></td><td><pre>    <span class=\"token keyword\">return</span> all_path_lengths</pre></td></tr><tr><td data-num=\"196\"></td><td><pre></pre></td></tr><tr><td data-num=\"197\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_pathlengths_for_two_sets</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> given_gene_set1<span class=\"token punctuation\">,</span> given_gene_set2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"198\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"199\"></td><td><pre>    计算两个给定基因集合中各基因对之间的最短路径长度。</pre></td></tr><tr><td data-num=\"200\"></td><td><pre>    结果存储在字典中：all_path_lengths[gene1][gene2] = l</pre></td></tr><tr><td data-num=\"201\"></td><td><pre>    其中 gene1 &lt; gene2，因此每对只存储一次</pre></td></tr><tr><td data-num=\"202\"></td><td><pre></pre></td></tr><tr><td data-num=\"203\"></td><td><pre>    参数：</pre></td></tr><tr><td data-num=\"204\"></td><td><pre>    - G: 网络</pre></td></tr><tr><td data-num=\"205\"></td><td><pre>    - gene_set1/2: 要计算路径的基因集</pre></td></tr><tr><td data-num=\"206\"></td><td><pre></pre></td></tr><tr><td data-num=\"207\"></td><td><pre>    返回：</pre></td></tr><tr><td data-num=\"208\"></td><td><pre>    - all_path_lengths[gene1][gene2] = l</pre></td></tr><tr><td data-num=\"209\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"210\"></td><td><pre></pre></td></tr><tr><td data-num=\"211\"></td><td><pre>    <span class=\"token comment\"># 去除不在网络中的节点</span></pre></td></tr><tr><td data-num=\"212\"></td><td><pre>    all_genes_in_network <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"213\"></td><td><pre>    gene_set1 <span class=\"token operator\">=</span> given_gene_set1 <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"214\"></td><td><pre>    gene_set2 <span class=\"token operator\">=</span> given_gene_set2 <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"215\"></td><td><pre></pre></td></tr><tr><td data-num=\"216\"></td><td><pre>    all_path_lengths <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"217\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"218\"></td><td><pre>    <span class=\"token comment\"># 计算所有可能对的距离</span></pre></td></tr><tr><td data-num=\"219\"></td><td><pre>    <span class=\"token keyword\">for</span> gene1 <span class=\"token keyword\">in</span> gene_set1<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"220\"></td><td><pre>        <span class=\"token keyword\">if</span> gene1 <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> all_path_lengths<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"221\"></td><td><pre>            all_path_lengths<span class=\"token punctuation\">[</span>gene1<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"222\"></td><td><pre>        <span class=\"token keyword\">for</span> gene2 <span class=\"token keyword\">in</span> gene_set2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"223\"></td><td><pre>            <span class=\"token keyword\">if</span> gene1 <span class=\"token operator\">!=</span> gene2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"224\"></td><td><pre>                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"225\"></td><td><pre>                    l <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>shortest_path_length<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> source<span class=\"token operator\">=</span>gene1<span class=\"token punctuation\">,</span> target<span class=\"token operator\">=</span>gene2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"226\"></td><td><pre>                    <span class=\"token keyword\">if</span> gene1 <span class=\"token operator\">&lt;</span> gene2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"227\"></td><td><pre>                        all_path_lengths<span class=\"token punctuation\">[</span>gene1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>gene2<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> l</pre></td></tr><tr><td data-num=\"228\"></td><td><pre>                    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"229\"></td><td><pre>                        <span class=\"token keyword\">if</span> gene2 <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> all_path_lengths<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"230\"></td><td><pre>                            all_path_lengths<span class=\"token punctuation\">[</span>gene2<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"231\"></td><td><pre>                        all_path_lengths<span class=\"token punctuation\">[</span>gene2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>gene1<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> l</pre></td></tr><tr><td data-num=\"232\"></td><td><pre>                <span class=\"token keyword\">except</span> nx<span class=\"token punctuation\">.</span>NetworkXNoPath<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"233\"></td><td><pre>                    <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"234\"></td><td><pre></pre></td></tr><tr><td data-num=\"235\"></td><td><pre>    <span class=\"token keyword\">return</span> all_path_lengths</pre></td></tr><tr><td data-num=\"236\"></td><td><pre></pre></td></tr><tr><td data-num=\"237\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">calc_single_set_distance</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> given_gene_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"238\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"239\"></td><td><pre>    计算给定网络中基因集合的平均最短距离</pre></td></tr><tr><td data-num=\"240\"></td><td><pre></pre></td></tr><tr><td data-num=\"241\"></td><td><pre>    参数：</pre></td></tr><tr><td data-num=\"242\"></td><td><pre>    - G: 网络</pre></td></tr><tr><td data-num=\"243\"></td><td><pre>    - gene_set: 要计算距离的基因集 </pre></td></tr><tr><td data-num=\"244\"></td><td><pre></pre></td></tr><tr><td data-num=\"245\"></td><td><pre>    返回：</pre></td></tr><tr><td data-num=\"246\"></td><td><pre>    - 平均最短距离 </pre></td></tr><tr><td data-num=\"247\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"248\"></td><td><pre></pre></td></tr><tr><td data-num=\"249\"></td><td><pre>    <span class=\"token comment\"># 去除不在网络中的节点</span></pre></td></tr><tr><td data-num=\"250\"></td><td><pre>    all_genes_in_network <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"251\"></td><td><pre>    gene_set <span class=\"token operator\">=</span> given_gene_set <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"252\"></td><td><pre></pre></td></tr><tr><td data-num=\"253\"></td><td><pre>    <span class=\"token comment\"># 获取所有基因对的网络距离</span></pre></td></tr><tr><td data-num=\"254\"></td><td><pre>    all_path_lengths <span class=\"token operator\">=</span> get_pathlengths_for_single_set<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"255\"></td><td><pre></pre></td></tr><tr><td data-num=\"256\"></td><td><pre>    all_distances <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"257\"></td><td><pre></pre></td></tr><tr><td data-num=\"258\"></td><td><pre>    <span class=\"token comment\"># 遍历所有基因对</span></pre></td></tr><tr><td data-num=\"259\"></td><td><pre>    <span class=\"token keyword\">for</span> geneA <span class=\"token keyword\">in</span> gene_set<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"260\"></td><td><pre>        all_distances_A <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"261\"></td><td><pre>        <span class=\"token keyword\">for</span> geneB <span class=\"token keyword\">in</span> gene_set<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"262\"></td><td><pre>            <span class=\"token keyword\">if</span> geneA <span class=\"token operator\">&lt;</span> geneB<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"263\"></td><td><pre>                <span class=\"token keyword\">if</span> geneB <span class=\"token keyword\">in</span> all_path_lengths<span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"264\"></td><td><pre>                    all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>all_path_lengths<span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"265\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"266\"></td><td><pre>                <span class=\"token keyword\">if</span> geneA <span class=\"token keyword\">in</span> all_path_lengths<span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"267\"></td><td><pre>                    all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>all_path_lengths<span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"268\"></td><td><pre></pre></td></tr><tr><td data-num=\"269\"></td><td><pre>        <span class=\"token keyword\">if</span> all_distances_A<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"270\"></td><td><pre>            l_min <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>all_distances_A<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"271\"></td><td><pre>            all_distances<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>l_min<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"272\"></td><td><pre></pre></td></tr><tr><td data-num=\"273\"></td><td><pre>    <span class=\"token comment\"># 计算平均最短距离</span></pre></td></tr><tr><td data-num=\"274\"></td><td><pre>    mean_shortest_distance <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>all_distances<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"275\"></td><td><pre></pre></td></tr><tr><td data-num=\"276\"></td><td><pre>    <span class=\"token keyword\">return</span> mean_shortest_distance</pre></td></tr><tr><td data-num=\"277\"></td><td><pre></pre></td></tr><tr><td data-num=\"278\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">calc_set_pair_distances</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> given_gene_set1<span class=\"token punctuation\">,</span> given_gene_set2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"279\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"280\"></td><td><pre>    计算给定网络中两个基因集合之间的平均最短距离</pre></td></tr><tr><td data-num=\"281\"></td><td><pre></pre></td></tr><tr><td data-num=\"282\"></td><td><pre>    参数：</pre></td></tr><tr><td data-num=\"283\"></td><td><pre>    - G: 网络</pre></td></tr><tr><td data-num=\"284\"></td><td><pre>    - gene_set1/2: 要计算距离的基因集 </pre></td></tr><tr><td data-num=\"285\"></td><td><pre></pre></td></tr><tr><td data-num=\"286\"></td><td><pre>    返回：</pre></td></tr><tr><td data-num=\"287\"></td><td><pre>    - 平均最短距离 </pre></td></tr><tr><td data-num=\"288\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"289\"></td><td><pre></pre></td></tr><tr><td data-num=\"290\"></td><td><pre>    <span class=\"token comment\"># 去除不在网络中的节点</span></pre></td></tr><tr><td data-num=\"291\"></td><td><pre>    all_genes_in_network <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"292\"></td><td><pre>    gene_set1 <span class=\"token operator\">=</span> given_gene_set1 <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"293\"></td><td><pre>    gene_set2 <span class=\"token operator\">=</span> given_gene_set2 <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"294\"></td><td><pre></pre></td></tr><tr><td data-num=\"295\"></td><td><pre>    <span class=\"token comment\"># 获取所有基因对的网络距离</span></pre></td></tr><tr><td data-num=\"296\"></td><td><pre>    all_path_lengths <span class=\"token operator\">=</span> get_pathlengths_for_two_sets<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set1<span class=\"token punctuation\">,</span> gene_set2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"297\"></td><td><pre></pre></td></tr><tr><td data-num=\"298\"></td><td><pre>    all_distances <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"299\"></td><td><pre></pre></td></tr><tr><td data-num=\"300\"></td><td><pre>    <span class=\"token comment\"># 遍历所有基因对，从集合 1 开始</span></pre></td></tr><tr><td data-num=\"301\"></td><td><pre>    <span class=\"token keyword\">for</span> geneA <span class=\"token keyword\">in</span> gene_set1<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"302\"></td><td><pre>        all_distances_A <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"303\"></td><td><pre>        <span class=\"token keyword\">for</span> geneB <span class=\"token keyword\">in</span> gene_set2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"304\"></td><td><pre>            <span class=\"token keyword\">if</span> geneA <span class=\"token operator\">==</span> geneB<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"305\"></td><td><pre>                all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"306\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"307\"></td><td><pre>                <span class=\"token keyword\">if</span> geneA <span class=\"token operator\">&lt;</span> geneB<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"308\"></td><td><pre>                    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"309\"></td><td><pre>                        all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>all_path_lengths<span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"310\"></td><td><pre>                    <span class=\"token keyword\">except</span> KeyError<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"311\"></td><td><pre>                        <span class=\"token keyword\">pass</span></pre></td></tr><tr><td data-num=\"312\"></td><td><pre>                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"313\"></td><td><pre>                    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"314\"></td><td><pre>                        all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>all_path_lengths<span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"315\"></td><td><pre>                    <span class=\"token keyword\">except</span> KeyError<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"316\"></td><td><pre>                        <span class=\"token keyword\">pass</span></pre></td></tr><tr><td data-num=\"317\"></td><td><pre></pre></td></tr><tr><td data-num=\"318\"></td><td><pre>        <span class=\"token keyword\">if</span> all_distances_A<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"319\"></td><td><pre>            l_min <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>all_distances_A<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"320\"></td><td><pre>            all_distances<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>l_min<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"321\"></td><td><pre></pre></td></tr><tr><td data-num=\"322\"></td><td><pre>    <span class=\"token comment\"># 遍历所有基因对，从集合 2 开始</span></pre></td></tr><tr><td data-num=\"323\"></td><td><pre>    <span class=\"token keyword\">for</span> geneA <span class=\"token keyword\">in</span> gene_set2<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"324\"></td><td><pre>        all_distances_A <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"325\"></td><td><pre>        <span class=\"token keyword\">for</span> geneB <span class=\"token keyword\">in</span> gene_set1<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"326\"></td><td><pre>            <span class=\"token keyword\">if</span> geneA <span class=\"token operator\">==</span> geneB<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"327\"></td><td><pre>                all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"328\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"329\"></td><td><pre>                <span class=\"token keyword\">if</span> geneA <span class=\"token operator\">&lt;</span> geneB<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"330\"></td><td><pre>                    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"331\"></td><td><pre>                        all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>all_path_lengths<span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"332\"></td><td><pre>                    <span class=\"token keyword\">except</span> KeyError<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"333\"></td><td><pre>                        <span class=\"token keyword\">pass</span></pre></td></tr><tr><td data-num=\"334\"></td><td><pre>                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"335\"></td><td><pre>                    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"336\"></td><td><pre>                        all_distances_A<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>all_path_lengths<span class=\"token punctuation\">[</span>geneB<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>geneA<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"337\"></td><td><pre>                    <span class=\"token keyword\">except</span> KeyError<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"338\"></td><td><pre>                        <span class=\"token keyword\">pass</span></pre></td></tr><tr><td data-num=\"339\"></td><td><pre></pre></td></tr><tr><td data-num=\"340\"></td><td><pre>        <span class=\"token keyword\">if</span> all_distances_A<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"341\"></td><td><pre>            l_min <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>all_distances_A<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"342\"></td><td><pre>            all_distances<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>l_min<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"343\"></td><td><pre></pre></td></tr><tr><td data-num=\"344\"></td><td><pre>    <span class=\"token comment\"># 计算平均最短距离</span></pre></td></tr><tr><td data-num=\"345\"></td><td><pre>    mean_shortest_distance <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>all_distances<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"346\"></td><td><pre></pre></td></tr><tr><td data-num=\"347\"></td><td><pre>    <span class=\"token keyword\">return</span> mean_shortest_distance</pre></td></tr><tr><td data-num=\"348\"></td><td><pre></pre></td></tr><tr><td data-num=\"349\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"350\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"351\"></td><td><pre></pre></td></tr><tr><td data-num=\"352\"></td><td><pre>           E N D    O F    D E F I N I T I O N S </pre></td></tr><tr><td data-num=\"353\"></td><td><pre></pre></td></tr><tr><td data-num=\"354\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"355\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"356\"></td><td><pre></pre></td></tr><tr><td data-num=\"357\"></td><td><pre><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"358\"></td><td><pre>    <span class=\"token comment\"># \"Hey Ho, Let's go!\" -- The Ramones (1976)</span></pre></td></tr><tr><td data-num=\"359\"></td><td><pre></pre></td></tr><tr><td data-num=\"360\"></td><td><pre>    parser <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>ArgumentParser<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"361\"></td><td><pre></pre></td></tr><tr><td data-num=\"362\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-u'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'--usage'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'print more info on how to use this script'</span><span class=\"token punctuation\">,</span> action<span class=\"token operator\">=</span><span class=\"token string\">'store_true'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"363\"></td><td><pre></pre></td></tr><tr><td data-num=\"364\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-n'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file containing the network edgelist [interactome.tsv]'</span><span class=\"token punctuation\">,</span> dest<span class=\"token operator\">=</span><span class=\"token string\">'network_file'</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token string\">'interactome.tsv'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"365\"></td><td><pre></pre></td></tr><tr><td data-num=\"366\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--g1'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file containing gene set 1'</span><span class=\"token punctuation\">,</span> dest<span class=\"token operator\">=</span><span class=\"token string\">'gene_file_1'</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token string\">'none'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"367\"></td><td><pre></pre></td></tr><tr><td data-num=\"368\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--g2'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file containing gene set 2'</span><span class=\"token punctuation\">,</span> dest<span class=\"token operator\">=</span><span class=\"token string\">'gene_file_2'</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token string\">'none'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"369\"></td><td><pre></pre></td></tr><tr><td data-num=\"370\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-o'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file for results [separation_results.txt]'</span><span class=\"token punctuation\">,</span> dest<span class=\"token operator\">=</span><span class=\"token string\">'results_file'</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token string\">'separation_results.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"371\"></td><td><pre></pre></td></tr><tr><td data-num=\"372\"></td><td><pre>    args <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>parse_args<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"373\"></td><td><pre></pre></td></tr><tr><td data-num=\"374\"></td><td><pre>    <span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>usage<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"375\"></td><td><pre>        print_usage<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"376\"></td><td><pre></pre></td></tr><tr><td data-num=\"377\"></td><td><pre>    network_file <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>network_file</pre></td></tr><tr><td data-num=\"378\"></td><td><pre>    gene_file_1 <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>gene_file_1</pre></td></tr><tr><td data-num=\"379\"></td><td><pre>    gene_file_2 <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>gene_file_2</pre></td></tr><tr><td data-num=\"380\"></td><td><pre>    results_file <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>results_file</pre></td></tr><tr><td data-num=\"381\"></td><td><pre></pre></td></tr><tr><td data-num=\"382\"></td><td><pre>    <span class=\"token comment\"># 检查输入文件：</span></pre></td></tr><tr><td data-num=\"383\"></td><td><pre>    <span class=\"token keyword\">if</span> gene_file_1 <span class=\"token operator\">==</span> <span class=\"token string\">'none'</span> <span class=\"token keyword\">or</span> gene_file_2 <span class=\"token operator\">==</span> <span class=\"token string\">'none'</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"384\"></td><td><pre>        error_message <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"385\"></td><td><pre>        ERROR: you must specify two files with gene sets, for example:</pre></td></tr><tr><td data-num=\"386\"></td><td><pre>        ./separation_py3.py --g1 MS.txt --g2 PD.txt</pre></td></tr><tr><td data-num=\"387\"></td><td><pre></pre></td></tr><tr><td data-num=\"388\"></td><td><pre>        For more information, type</pre></td></tr><tr><td data-num=\"389\"></td><td><pre>        ./separation_py3.py --usage</pre></td></tr><tr><td data-num=\"390\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"391\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>error_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"392\"></td><td><pre>        sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"393\"></td><td><pre></pre></td></tr><tr><td data-num=\"394\"></td><td><pre>    <span class=\"token keyword\">if</span> network_file <span class=\"token operator\">==</span> <span class=\"token string\">'interactome.tsv'</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"395\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'> default network from \"interactome.tsv\" will be used'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"396\"></td><td><pre></pre></td></tr><tr><td data-num=\"397\"></td><td><pre>    <span class=\"token comment\"># 读取网络和疾病基因集</span></pre></td></tr><tr><td data-num=\"398\"></td><td><pre>    G <span class=\"token operator\">=</span> read_network<span class=\"token punctuation\">(</span>network_file<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"399\"></td><td><pre>    all_genes_in_network <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"400\"></td><td><pre>    remove_self_links<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"401\"></td><td><pre></pre></td></tr><tr><td data-num=\"402\"></td><td><pre>    <span class=\"token comment\"># 读取基因集 1</span></pre></td></tr><tr><td data-num=\"403\"></td><td><pre>    genes_A_full <span class=\"token operator\">=</span> read_gene_list<span class=\"token punctuation\">(</span>gene_file_1<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"404\"></td><td><pre>    genes_A <span class=\"token operator\">=</span> genes_A_full <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"405\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_A_full<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_A<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"406\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> ignoring &#123;&#125; genes that are not in the network\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_A_full <span class=\"token operator\">-</span> all_genes_in_network<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"407\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> remaining number of genes: &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_A<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"408\"></td><td><pre></pre></td></tr><tr><td data-num=\"409\"></td><td><pre>    <span class=\"token comment\"># 读取基因集 2</span></pre></td></tr><tr><td data-num=\"410\"></td><td><pre>    genes_B_full <span class=\"token operator\">=</span> read_gene_list<span class=\"token punctuation\">(</span>gene_file_2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"411\"></td><td><pre>    genes_B <span class=\"token operator\">=</span> genes_B_full <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"412\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_B_full<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_B<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"413\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> ignoring &#123;&#125; genes that are not in the network\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_B_full <span class=\"token operator\">-</span> all_genes_in_network<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"414\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> remaining number of genes: &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_B<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"415\"></td><td><pre></pre></td></tr><tr><td data-num=\"416\"></td><td><pre>    <span class=\"token comment\"># 计算网络量化指标</span></pre></td></tr><tr><td data-num=\"417\"></td><td><pre>    d_A <span class=\"token operator\">=</span> calc_single_set_distance<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> genes_A<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"418\"></td><td><pre>    d_B <span class=\"token operator\">=</span> calc_single_set_distance<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> genes_B<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"419\"></td><td><pre>    d_AB <span class=\"token operator\">=</span> calc_set_pair_distances<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> genes_A<span class=\"token punctuation\">,</span> genes_B<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"420\"></td><td><pre></pre></td></tr><tr><td data-num=\"421\"></td><td><pre>    s_AB <span class=\"token operator\">=</span> d_AB <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span>d_A <span class=\"token operator\">+</span> d_B<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2.0</span></pre></td></tr><tr><td data-num=\"422\"></td><td><pre></pre></td></tr><tr><td data-num=\"423\"></td><td><pre>    results_message <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"424\"></td><td><pre>> gene set A from \"&#123;&#125;\": &#123;&#125; genes, network-diameter d_A = &#123;&#125;</pre></td></tr><tr><td data-num=\"425\"></td><td><pre>> gene set B from \"&#123;&#125;\": &#123;&#125; genes, network-diameter d_B = &#123;&#125;</pre></td></tr><tr><td data-num=\"426\"></td><td><pre>> mean shortest distance between A &amp; B: d_AB = &#123;&#125; </pre></td></tr><tr><td data-num=\"427\"></td><td><pre>> network separation of A &amp; B:          s_AB = &#123;&#125;</pre></td></tr><tr><td data-num=\"428\"></td><td><pre>\"\"\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>gene_file_1<span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_A<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> d_A<span class=\"token punctuation\">,</span> gene_file_2<span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>genes_B<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> d_B<span class=\"token punctuation\">,</span> d_AB<span class=\"token punctuation\">,</span> s_AB<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"429\"></td><td><pre></pre></td></tr><tr><td data-num=\"430\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>results_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"431\"></td><td><pre></pre></td></tr><tr><td data-num=\"432\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>results_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fp<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"433\"></td><td><pre>        fp<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>results_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"434\"></td><td><pre></pre></td></tr><tr><td data-num=\"435\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> results have been saved to &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>results_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h3 id=\"localization_py3py\"><a class=\"anchor\" href=\"#localization_py3py\">#</a> localization_py3.py</h3>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#! /usr/bin/env python3</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"4\"></td><td><pre># -----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"6\"></td><td><pre># localization_py3.py</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"8\"></td><td><pre># by Joerg Menche</pre></td></tr><tr><td data-num=\"9\"></td><td><pre># Last Modified: 2014-12-06</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"11\"></td><td><pre># This code determines the network-based distance and separation for</pre></td></tr><tr><td data-num=\"12\"></td><td><pre># two given sets of nodes on a given network as described in </pre></td></tr><tr><td data-num=\"13\"></td><td><pre># </pre></td></tr><tr><td data-num=\"14\"></td><td><pre># Uncovering Disease-Disease Relationships Through The Human</pre></td></tr><tr><td data-num=\"15\"></td><td><pre># Interactome</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"17\"></td><td><pre># by Joerg Menche, Amitabh Sharma, Maksim Kitsak, Susan Dina</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>#    Ghiassian, Marc Vidal, Joseph Loscalzo &amp; Albert-Laszlo Barabasi</pre></td></tr><tr><td data-num=\"19\"></td><td><pre># </pre></td></tr><tr><td data-num=\"20\"></td><td><pre># -----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"21\"></td><td><pre># </pre></td></tr><tr><td data-num=\"22\"></td><td><pre># This program will calculate the size of the largest connected</pre></td></tr><tr><td data-num=\"23\"></td><td><pre># component S and mean shortest distance &lt;d_s> for a given gene</pre></td></tr><tr><td data-num=\"24\"></td><td><pre># set. It will also compute the expected lcc size for the same number</pre></td></tr><tr><td data-num=\"25\"></td><td><pre># of randomly distributed genes.</pre></td></tr><tr><td data-num=\"26\"></td><td><pre># </pre></td></tr><tr><td data-num=\"27\"></td><td><pre># * Required input:</pre></td></tr><tr><td data-num=\"28\"></td><td><pre># </pre></td></tr><tr><td data-num=\"29\"></td><td><pre>#   a file containing a gene set. The file must be in form of a table,</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>#   one gene per line. If the table contains several columns, they</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>#   must be tab-separated, only the first column will be used. See the</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>#   two files MS.txt and PD.txt for valid examples (they contain genes</pre></td></tr><tr><td data-num=\"33\"></td><td><pre>#   for multiple sclerosis and peroxisomal disorders, respectively).</pre></td></tr><tr><td data-num=\"34\"></td><td><pre># </pre></td></tr><tr><td data-num=\"35\"></td><td><pre># * Optional input:  </pre></td></tr><tr><td data-num=\"36\"></td><td><pre># </pre></td></tr><tr><td data-num=\"37\"></td><td><pre>#   - file containing an interaction network. If no file is given, the</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>#     default network \"interactome.tsv\" will be used instead. The file</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>#     must contain an edgelist provided as a tab-separated table. The</pre></td></tr><tr><td data-num=\"40\"></td><td><pre>#     first two columns of the table will be interpreted as an</pre></td></tr><tr><td data-num=\"41\"></td><td><pre>#     interaction gene1 &lt;==> gene2</pre></td></tr><tr><td data-num=\"42\"></td><td><pre># </pre></td></tr><tr><td data-num=\"43\"></td><td><pre>#  - filename for the output. If none is given,</pre></td></tr><tr><td data-num=\"44\"></td><td><pre>#    \"localization_results.txt\" will be used</pre></td></tr><tr><td data-num=\"45\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"46\"></td><td><pre>#  - the number or random simulations can be chosen. Default is 1000,</pre></td></tr><tr><td data-num=\"47\"></td><td><pre>#    which should run fast even for large gene sets and typically</pre></td></tr><tr><td data-num=\"48\"></td><td><pre>#    gives good results. </pre></td></tr><tr><td data-num=\"49\"></td><td><pre># </pre></td></tr><tr><td data-num=\"50\"></td><td><pre># Here's an example that should work, provided the files are in the same</pre></td></tr><tr><td data-num=\"51\"></td><td><pre># directory as this python script:</pre></td></tr><tr><td data-num=\"52\"></td><td><pre># </pre></td></tr><tr><td data-num=\"53\"></td><td><pre># ./localization_py3.py -n interactome.tsv -g PD.txt -o output.txt</pre></td></tr><tr><td data-num=\"54\"></td><td><pre># </pre></td></tr><tr><td data-num=\"55\"></td><td><pre>#</pre></td></tr><tr><td data-num=\"56\"></td><td><pre># -----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"57\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre></pre></td></tr><tr><td data-num=\"59\"></td><td><pre><span class=\"token keyword\">import</span> networkx <span class=\"token keyword\">as</span> nx</pre></td></tr><tr><td data-num=\"60\"></td><td><pre><span class=\"token keyword\">import</span> random </pre></td></tr><tr><td data-num=\"61\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"62\"></td><td><pre><span class=\"token keyword\">import</span> argparse</pre></td></tr><tr><td data-num=\"63\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"64\"></td><td><pre></pre></td></tr><tr><td data-num=\"65\"></td><td><pre><span class=\"token keyword\">import</span> separation_py3 <span class=\"token keyword\">as</span> tools</pre></td></tr><tr><td data-num=\"66\"></td><td><pre></pre></td></tr><tr><td data-num=\"67\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"68\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"69\"></td><td><pre></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>           S T A R T   D E F I N I T I O N S </pre></td></tr><tr><td data-num=\"71\"></td><td><pre></pre></td></tr><tr><td data-num=\"72\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"73\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre></pre></td></tr><tr><td data-num=\"75\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">print_usage</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"77\"></td><td><pre>    打印使用说明</pre></td></tr><tr><td data-num=\"78\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>    usage_message <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"80\"></td><td><pre># ----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"81\"></td><td><pre></pre></td></tr><tr><td data-num=\"82\"></td><td><pre>This program will calculate the network-based localization for a given</pre></td></tr><tr><td data-num=\"83\"></td><td><pre>gene set</pre></td></tr><tr><td data-num=\"84\"></td><td><pre></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>* Required input:</pre></td></tr><tr><td data-num=\"86\"></td><td><pre></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>  one file containing a gene set. The file must be in form of a</pre></td></tr><tr><td data-num=\"88\"></td><td><pre>  table, one gene per line. If the table contains several columns,</pre></td></tr><tr><td data-num=\"89\"></td><td><pre>  they must be tab-separated, only the first column will be used. See</pre></td></tr><tr><td data-num=\"90\"></td><td><pre>  the two files MS.txt and PD.txt for valid examples (they contain</pre></td></tr><tr><td data-num=\"91\"></td><td><pre>  genes for multiple sclerosis and peroxisomal disorders).</pre></td></tr><tr><td data-num=\"92\"></td><td><pre></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>* Optional input:  </pre></td></tr><tr><td data-num=\"94\"></td><td><pre></pre></td></tr><tr><td data-num=\"95\"></td><td><pre>  - file containing an interaction network. If no file is given, the</pre></td></tr><tr><td data-num=\"96\"></td><td><pre>    default network \\\"interactome.tsv\\\" will be used instead. The file</pre></td></tr><tr><td data-num=\"97\"></td><td><pre>    must contain an edgelist provided as a tab-separated table. The</pre></td></tr><tr><td data-num=\"98\"></td><td><pre>    first two columns of the table will be interpreted as an</pre></td></tr><tr><td data-num=\"99\"></td><td><pre>    interaction gene1 &lt;==> gene2</pre></td></tr><tr><td data-num=\"100\"></td><td><pre></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>  - filename for the output. If none is given,</pre></td></tr><tr><td data-num=\"102\"></td><td><pre>    \\\"localization_results.txt\\\" will be used</pre></td></tr><tr><td data-num=\"103\"></td><td><pre></pre></td></tr><tr><td data-num=\"104\"></td><td><pre>  - the number or random simulations can be chosen. Default is 1000,</pre></td></tr><tr><td data-num=\"105\"></td><td><pre>    which should run fast even for large gene sets and typically gives</pre></td></tr><tr><td data-num=\"106\"></td><td><pre>    good results.</pre></td></tr><tr><td data-num=\"107\"></td><td><pre></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>Here's an example that should work, provided the files are in the same</pre></td></tr><tr><td data-num=\"109\"></td><td><pre>directory as this python script:</pre></td></tr><tr><td data-num=\"110\"></td><td><pre></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>./localization_py3.py -n interactome.tsv -g PD.txt -o output.txt</pre></td></tr><tr><td data-num=\"112\"></td><td><pre></pre></td></tr><tr><td data-num=\"113\"></td><td><pre># ----------------------------------------------------------------------</pre></td></tr><tr><td data-num=\"114\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"115\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>usage_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"116\"></td><td><pre>    sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"117\"></td><td><pre></pre></td></tr><tr><td data-num=\"118\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_lcc_size</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> seed_nodes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"120\"></td><td><pre>    返回最大连通组件的大小</pre></td></tr><tr><td data-num=\"121\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>    g <span class=\"token operator\">=</span> G<span class=\"token punctuation\">.</span>subgraph<span class=\"token punctuation\">(</span>seed_nodes<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"123\"></td><td><pre></pre></td></tr><tr><td data-num=\"124\"></td><td><pre>    <span class=\"token keyword\">if</span> g<span class=\"token punctuation\">.</span>number_of_nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>        components <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>connected_components<span class=\"token punctuation\">(</span>g<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"126\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span>components<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"127\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"129\"></td><td><pre></pre></td></tr><tr><td data-num=\"130\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_random_comparison</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set<span class=\"token punctuation\">,</span> sims<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"131\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"132\"></td><td><pre>    获取随机基因集的最大连通组件大小期望值</pre></td></tr><tr><td data-num=\"133\"></td><td><pre></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>    参数：</pre></td></tr><tr><td data-num=\"135\"></td><td><pre>    - G: 网络</pre></td></tr><tr><td data-num=\"136\"></td><td><pre>    - gene_set: 基因集</pre></td></tr><tr><td data-num=\"137\"></td><td><pre>    - sims: 随机模拟次数</pre></td></tr><tr><td data-num=\"138\"></td><td><pre></pre></td></tr><tr><td data-num=\"139\"></td><td><pre>    返回：</pre></td></tr><tr><td data-num=\"140\"></td><td><pre>    - 包含结果的字符串</pre></td></tr><tr><td data-num=\"141\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"142\"></td><td><pre>    all_genes <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"143\"></td><td><pre>    number_of_seed_genes <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gene_set <span class=\"token operator\">&amp;</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>all_genes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"144\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"145\"></td><td><pre>    l_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"146\"></td><td><pre></pre></td></tr><tr><td data-num=\"147\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"148\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sims <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"149\"></td><td><pre>        <span class=\"token keyword\">if</span> i <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"150\"></td><td><pre>            sys<span class=\"token punctuation\">.</span>stdout<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string\">\"> random simulation [&#123;&#125; of &#123;&#125;]\\r\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> sims<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>            sys<span class=\"token punctuation\">.</span>stdout<span class=\"token punctuation\">.</span>flush<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"152\"></td><td><pre></pre></td></tr><tr><td data-num=\"153\"></td><td><pre>        rand_seeds <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span>all_genes<span class=\"token punctuation\">,</span> number_of_seed_genes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"154\"></td><td><pre>        lcc <span class=\"token operator\">=</span> get_lcc_size<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> rand_seeds<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"155\"></td><td><pre>        l_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>lcc<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"156\"></td><td><pre></pre></td></tr><tr><td data-num=\"157\"></td><td><pre>    lcc_observed <span class=\"token operator\">=</span> get_lcc_size<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"158\"></td><td><pre>    l_mean <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>l_list<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"159\"></td><td><pre>    l_std <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span>l_list<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"160\"></td><td><pre></pre></td></tr><tr><td data-num=\"161\"></td><td><pre>    <span class=\"token keyword\">if</span> l_std <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"162\"></td><td><pre>        z_score <span class=\"token operator\">=</span> <span class=\"token string\">'not available'</span></pre></td></tr><tr><td data-num=\"163\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"164\"></td><td><pre>        z_score <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>lcc_observed <span class=\"token operator\">-</span> l_mean<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> l_std</pre></td></tr><tr><td data-num=\"165\"></td><td><pre></pre></td></tr><tr><td data-num=\"166\"></td><td><pre>    results_message <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"167\"></td><td><pre>> Random expectation:</pre></td></tr><tr><td data-num=\"168\"></td><td><pre>> lcc [rand] = &#123;&#125;</pre></td></tr><tr><td data-num=\"169\"></td><td><pre>> => z-score of observed lcc = &#123;&#125;</pre></td></tr><tr><td data-num=\"170\"></td><td><pre>\"\"\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>l_mean<span class=\"token punctuation\">,</span> z_score<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"171\"></td><td><pre></pre></td></tr><tr><td data-num=\"172\"></td><td><pre>    <span class=\"token keyword\">return</span> results_message</pre></td></tr><tr><td data-num=\"173\"></td><td><pre></pre></td></tr><tr><td data-num=\"174\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"175\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"176\"></td><td><pre></pre></td></tr><tr><td data-num=\"177\"></td><td><pre>           E N D    O F    D E F I N I T I O N S </pre></td></tr><tr><td data-num=\"178\"></td><td><pre></pre></td></tr><tr><td data-num=\"179\"></td><td><pre># =============================================================================</pre></td></tr><tr><td data-num=\"180\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"181\"></td><td><pre></pre></td></tr><tr><td data-num=\"182\"></td><td><pre><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"183\"></td><td><pre></pre></td></tr><tr><td data-num=\"184\"></td><td><pre>    <span class=\"token comment\"># \"Hey Ho, Let's go!\" -- The Ramones (1976)</span></pre></td></tr><tr><td data-num=\"185\"></td><td><pre></pre></td></tr><tr><td data-num=\"186\"></td><td><pre>    parser <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>ArgumentParser<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"187\"></td><td><pre></pre></td></tr><tr><td data-num=\"188\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-u'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'--usage'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"189\"></td><td><pre>                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'print more info on how to use this script'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"190\"></td><td><pre>                        action<span class=\"token operator\">=</span><span class=\"token string\">'store_true'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"191\"></td><td><pre></pre></td></tr><tr><td data-num=\"192\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-n'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"193\"></td><td><pre>                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file containing the network edgelist [interactome.tsv]'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"194\"></td><td><pre>                        dest<span class=\"token operator\">=</span><span class=\"token string\">'network_file'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"195\"></td><td><pre>                        default<span class=\"token operator\">=</span><span class=\"token string\">'interactome.tsv'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"196\"></td><td><pre>                        <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"197\"></td><td><pre></pre></td></tr><tr><td data-num=\"198\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-g'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"199\"></td><td><pre>                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file containing gene set'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"200\"></td><td><pre>                        dest<span class=\"token operator\">=</span><span class=\"token string\">'gene_file'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"201\"></td><td><pre>                        default<span class=\"token operator\">=</span><span class=\"token string\">'none'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"202\"></td><td><pre>                        <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"203\"></td><td><pre></pre></td></tr><tr><td data-num=\"204\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-s'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"205\"></td><td><pre>                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'number of random simulations [1000]'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"206\"></td><td><pre>                        dest<span class=\"token operator\">=</span><span class=\"token string\">'sims'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"207\"></td><td><pre>                        default<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"208\"></td><td><pre>                        <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"209\"></td><td><pre></pre></td></tr><tr><td data-num=\"210\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-o'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"211\"></td><td><pre>                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'file for results [localization_results.txt]'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"212\"></td><td><pre>                        dest<span class=\"token operator\">=</span><span class=\"token string\">'results_file'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"213\"></td><td><pre>                        default<span class=\"token operator\">=</span><span class=\"token string\">'localization_results.txt'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"214\"></td><td><pre>                        <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"215\"></td><td><pre></pre></td></tr><tr><td data-num=\"216\"></td><td><pre>    args <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>parse_args<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"217\"></td><td><pre></pre></td></tr><tr><td data-num=\"218\"></td><td><pre>    <span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>usage<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"219\"></td><td><pre>        print_usage<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"220\"></td><td><pre></pre></td></tr><tr><td data-num=\"221\"></td><td><pre>    network_file <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>network_file</pre></td></tr><tr><td data-num=\"222\"></td><td><pre>    gene_file <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>gene_file</pre></td></tr><tr><td data-num=\"223\"></td><td><pre>    results_file <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>results_file</pre></td></tr><tr><td data-num=\"224\"></td><td><pre>    sims <span class=\"token operator\">=</span> args<span class=\"token punctuation\">.</span>sims</pre></td></tr><tr><td data-num=\"225\"></td><td><pre></pre></td></tr><tr><td data-num=\"226\"></td><td><pre>    <span class=\"token keyword\">if</span> gene_file <span class=\"token operator\">==</span> <span class=\"token string\">'none'</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"227\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"228\"></td><td><pre>        ERROR: you must specify an input file with a gene set, for example:</pre></td></tr><tr><td data-num=\"229\"></td><td><pre>        ./localization_py3.py -g MS.txt</pre></td></tr><tr><td data-num=\"230\"></td><td><pre></pre></td></tr><tr><td data-num=\"231\"></td><td><pre>        For more information, type</pre></td></tr><tr><td data-num=\"232\"></td><td><pre>        ./localization_py3.py --usage</pre></td></tr><tr><td data-num=\"233\"></td><td><pre>        \"\"\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"234\"></td><td><pre>        sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"235\"></td><td><pre></pre></td></tr><tr><td data-num=\"236\"></td><td><pre>    <span class=\"token keyword\">if</span> network_file <span class=\"token operator\">==</span> <span class=\"token string\">'interactome.tsv'</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"237\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'> default network from \"interactome.tsv\" will be used'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"238\"></td><td><pre></pre></td></tr><tr><td data-num=\"239\"></td><td><pre>    G <span class=\"token operator\">=</span> tools<span class=\"token punctuation\">.</span>read_network<span class=\"token punctuation\">(</span>network_file<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"240\"></td><td><pre>    all_genes_in_network <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">.</span>nodes<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"241\"></td><td><pre>    tools<span class=\"token punctuation\">.</span>remove_self_links<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"242\"></td><td><pre></pre></td></tr><tr><td data-num=\"243\"></td><td><pre>    gene_set_full <span class=\"token operator\">=</span> tools<span class=\"token punctuation\">.</span>read_gene_list<span class=\"token punctuation\">(</span>gene_file<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"244\"></td><td><pre>    gene_set <span class=\"token operator\">=</span> gene_set_full <span class=\"token operator\">&amp;</span> all_genes_in_network</pre></td></tr><tr><td data-num=\"245\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gene_set_full<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gene_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"246\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> ignoring &#123;&#125; genes that are not in the network\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"247\"></td><td><pre>            <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gene_set_full <span class=\"token operator\">-</span> all_genes_in_network<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"248\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> remaining number of genes: &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gene_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"249\"></td><td><pre></pre></td></tr><tr><td data-num=\"250\"></td><td><pre>    lcc <span class=\"token operator\">=</span> get_lcc_size<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"251\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n> lcc size = &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>lcc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"252\"></td><td><pre></pre></td></tr><tr><td data-num=\"253\"></td><td><pre>    d_s <span class=\"token operator\">=</span> tools<span class=\"token punctuation\">.</span>calc_single_set_distance<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"254\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> mean shortest distance = &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>d_s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"255\"></td><td><pre></pre></td></tr><tr><td data-num=\"256\"></td><td><pre>    results_message <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"257\"></td><td><pre>> gene set from \"&#123;&#125;\": &#123;&#125; genes</pre></td></tr><tr><td data-num=\"258\"></td><td><pre>> lcc  size  S = &#123;&#125;</pre></td></tr><tr><td data-num=\"259\"></td><td><pre>> diameter d_s = &#123;&#125;</pre></td></tr><tr><td data-num=\"260\"></td><td><pre>\"\"\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>gene_file<span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>gene_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lcc<span class=\"token punctuation\">,</span> d_s<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"261\"></td><td><pre></pre></td></tr><tr><td data-num=\"262\"></td><td><pre>    results_message <span class=\"token operator\">+=</span> get_random_comparison<span class=\"token punctuation\">(</span>G<span class=\"token punctuation\">,</span> gene_set<span class=\"token punctuation\">,</span> sims<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"263\"></td><td><pre></pre></td></tr><tr><td data-num=\"264\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>results_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"265\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"266\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>results_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fp<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"267\"></td><td><pre>        fp<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>results_message<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"268\"></td><td><pre></pre></td></tr><tr><td data-num=\"269\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"> results have been saved to &#123;&#125;\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>results_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h2 id=\"参考\"><a class=\"anchor\" href=\"#参考\">#</a> 参考</h2>\n<ol>\n<li><a href=\"https://www.science.org/doi/full/10.1126/science.1257601\">Uncovering disease-disease relationships through the incomplete interactome</a></li>\n</ol>\n",
            "tags": [
                "Python",
                "network",
                "interactome"
            ]
        },
        {
            "id": "https://new.limina.top/2024/07/01/%E4%BD%BF%E7%94%A8%20Entrez%20API%20%E8%BF%9B%E8%A1%8C%20PubMed%20%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/",
            "url": "https://new.limina.top/2024/07/01/%E4%BD%BF%E7%94%A8%20Entrez%20API%20%E8%BF%9B%E8%A1%8C%20PubMed%20%E6%96%87%E7%8C%AE%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/",
            "title": "使用 Entrez API 进行 PubMed 文献信息提取",
            "date_published": "2024-06-30T18:58:06.000Z",
            "content_html": "<h1 id=\"使用-entrez-api-进行-pubmed-文献信息提取\"><a class=\"anchor\" href=\"#使用-entrez-api-进行-pubmed-文献信息提取\">#</a> 使用 Entrez API 进行 PubMed 文献信息提取</h1>\n<blockquote>\n<p>PubMed 是一个常用的文献数据库，提供了大量生物医学领域的文献。当需要整理大量文献时，手动搜索可能会非常耗时。</p>\n<p>我们可以使用 Entrez API 自动化这一过程。本文将介绍如何使用 Python 和 Entrez API 提取 PubMed 文献信息，并将结果保存为 CSV 文件。</p>\n</blockquote>\n<p><img loading=\"lazy\" data-src=\"https://img.limina.top/blog/image-20240703184324447.png\" alt=\"image-20240703184324447\" /></p>\n<h2 id=\"环境准备\"><a class=\"anchor\" href=\"#环境准备\">#</a> 环境准备</h2>\n<p>首先，我们需要安装 Biopython，这是一个用于生物信息学的强大工具包，包含了访问 Entrez API 的模块。</p>\n<figure class=\"highlight sh\"><figcaption data-lang=\"sh\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pip <span class=\"token function\">install</span> biopython</pre></td></tr></table></figure><p>此外，还需要一些其他的 Python 库：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> Bio <span class=\"token keyword\">import</span> Entrez<span class=\"token punctuation\">,</span> Medline</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> time</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> urllib<span class=\"token punctuation\">.</span>error <span class=\"token keyword\">import</span> HTTPError</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> ssl</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">import</span> urllib3</pre></td></tr></table></figure><p>为了避免 SSL 证书验证错误，我们可以禁用证书验证和警告：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 禁用警告和证书验证</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>urllib3<span class=\"token punctuation\">.</span>disable_warnings<span class=\"token punctuation\">(</span>urllib3<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>InsecureRequestWarning<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>ssl<span class=\"token punctuation\">.</span>_create_default_https_context <span class=\"token operator\">=</span> ssl<span class=\"token punctuation\">.</span>_create_unverified_context</pre></td></tr></table></figure><p>接下来，设置 NCBI 账户的邮箱（需要在 NCBI 网站上注册一个账户）：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Entrez<span class=\"token punctuation\">.</span>email <span class=\"token operator\">=</span> <span class=\"token string\">\"your_email@example.com\"</span></pre></td></tr></table></figure><h2 id=\"提取日期的正则表达式模式\"><a class=\"anchor\" href=\"#提取日期的正则表达式模式\">#</a> 提取日期的正则表达式模式</h2>\n<p>为了处理日期信息，我们定义了一个正则表达式模式：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>date_pattern <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token string\">r'\\b\\d&#123;4&#125; \\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\b \\d&#123;1,2&#125;'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h2 id=\"定义函数\"><a class=\"anchor\" href=\"#定义函数\">#</a> 定义函数</h2>\n<h3 id=\"fetch_pubmed_data-函数\"><a class=\"anchor\" href=\"#fetch_pubmed_data-函数\">#</a> fetch_pubmed_data 函数</h3>\n<p>这个函数从 PubMed 获取文献信息并保存到 CSV 文件中。</p>\n<p>由于 Entrez API 最多只能获取检索到的前 9999 篇（其实在网页上我们也只能看到检索到的文献的前 10000 篇），若使用检索词检索到的文章数量少于 10000 篇，则直接获取文献 PMID 列表；否则，按年份分段进行检索以获取所有文献的 PMID 列表。</p>\n<p>这种方法可以应付大多数的情况，即一年发文不超过 9999 篇的情况。但如果你的关键词检索结果显示有些年份的发文数量仍然大于 9999 篇，你可以自行修改此处的逻辑，如按照月份来重构检索词。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">fetch_pubmed_data</span><span class=\"token punctuation\">(</span>term<span class=\"token punctuation\">,</span> fname<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    从 PubMed 获取文献信息并保存到 CSV 文件。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    参数:</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    - term: 检索词</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    - fname: 保存文件名</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>term<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    retmax <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"Count\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    pmid_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token keyword\">if</span> retmax <span class=\"token operator\">&lt;</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>term<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span>retmax<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"IdList\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        start_year <span class=\"token operator\">=</span> <span class=\"token number\">2004</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        end_year <span class=\"token operator\">=</span> <span class=\"token number\">2024</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token keyword\">for</span> year <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>start_year<span class=\"token punctuation\">,</span> end_year <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>            subterm <span class=\"token operator\">=</span> term <span class=\"token operator\">+</span> <span class=\"token string-interpolation\"><span class=\"token string\">f' AND ((\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>year<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"[Date - Publication] : \"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>year<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"[Date - Publication]))'</span></span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>            handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>subterm<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>            retmax <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"Count\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>            handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>subterm<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span>retmax<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>            record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>            handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>            pmid_list <span class=\"token operator\">+=</span> record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"IdList\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> <span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>    data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>            <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>                handle_efetch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>efetch<span class=\"token punctuation\">(</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span><span class=\"token operator\">=</span>pmid_list<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">:</span>i <span class=\"token operator\">+</span> <span class=\"token number\">50</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> rettype<span class=\"token operator\">=</span><span class=\"token string\">'medline'</span><span class=\"token punctuation\">,</span> retmode<span class=\"token operator\">=</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>                records_efetch <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>Medline<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>handle_efetch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>                handle_efetch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>                <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>            <span class=\"token keyword\">except</span> HTTPError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>                <span class=\"token keyword\">if</span> e<span class=\"token punctuation\">.</span>code <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">429</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>                    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"efetch: HTTP错误 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">.</span>code<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">，5 秒后重试...\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>                    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>                    <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>                    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"efetch: HTTP错误: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>                    <span class=\"token keyword\">raise</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>            <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"efetch: Error: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>                time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>        <span class=\"token keyword\">for</span> record_efetch <span class=\"token keyword\">in</span> records_efetch<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>            PMID <span class=\"token operator\">=</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>            linked<span class=\"token punctuation\">,</span> references <span class=\"token operator\">=</span> fetch_citation_data<span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>            publication_date <span class=\"token operator\">=</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'SO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>            <span class=\"token keyword\">match</span> <span class=\"token operator\">=</span> date_pattern<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>publication_date<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>            formatted_publication_date <span class=\"token operator\">=</span> <span class=\"token keyword\">match</span><span class=\"token punctuation\">.</span>group<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> <span class=\"token keyword\">match</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>            record_dict <span class=\"token operator\">=</span> create_record_dict<span class=\"token punctuation\">(</span>record_efetch<span class=\"token punctuation\">,</span> formatted_publication_date<span class=\"token punctuation\">,</span> linked<span class=\"token punctuation\">,</span> references<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>            data<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>record_dict<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'已成功获取 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 篇文献信息'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>            df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>fname<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h3 id=\"fetch_citation_data-函数\"><a class=\"anchor\" href=\"#fetch_citation_data-函数\">#</a> fetch_citation_data 函数</h3>\n<p>这个函数获取文章的引用和参考文献信息：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">fetch_citation_data</span><span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    获取引用和参考文献信息。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    参数:</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    - PMID: PubMed 标识符</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    返回值:</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    - linked: 引用 PMID 列表</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    - references: 参考文献 PMID 列表</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    linked <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    references <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>            handle_elink <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>elink<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span><span class=\"token operator\">=</span>PMID<span class=\"token punctuation\">,</span> linkname<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed_pubmed_citedin,pubmed_pubmed_refs\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>            record_elink <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_elink<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>            handle_elink<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>            <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        <span class=\"token keyword\">except</span> HTTPError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>            <span class=\"token keyword\">if</span> e<span class=\"token punctuation\">.</span>code <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">429</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"elink: HTTP错误 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">.</span>code<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">，5 秒后重试...\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>                time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"elink: HTTP错误: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>                <span class=\"token keyword\">raise</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"elink: Error: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>            <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    <span class=\"token keyword\">if</span> record_elink <span class=\"token keyword\">and</span> <span class=\"token string\">\"LinkSetDb\"</span> <span class=\"token keyword\">in</span> record_elink<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        <span class=\"token keyword\">for</span> linkset <span class=\"token keyword\">in</span> record_elink<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkSetDb\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>            <span class=\"token keyword\">if</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkName\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"pubmed_pubmed_citedin\"</span> <span class=\"token keyword\">and</span> <span class=\"token string\">\"Link\"</span> <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>                linked<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">\"Id\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"Link\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>            <span class=\"token keyword\">elif</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkName\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"pubmed_pubmed_refs\"</span> <span class=\"token keyword\">and</span> <span class=\"token string\">\"Link\"</span> <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>                references<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">\"Id\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"Link\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token keyword\">return</span> linked<span class=\"token punctuation\">,</span> references</pre></td></tr></table></figure><h3 id=\"create_record_dict-函数\"><a class=\"anchor\" href=\"#create_record_dict-函数\">#</a> create_record_dict 函数</h3>\n<p>这个函数创建一个包含文章详细信息的字典：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">create_record_dict</span><span class=\"token punctuation\">(</span>record_efetch<span class=\"token punctuation\">,</span> publication_date<span class=\"token punctuation\">,</span> linked<span class=\"token punctuation\">,</span> references<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    创建记录字典。</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    参数:</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    - record_efetch: 文章记录</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    - publication_date: 正式发表日期</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    - linked: 引用 PMID 列表</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    - references: 参考文献 PMID 列表</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    返回值:</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    - record_dict: 记录字典</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token string\">'Title'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'TI'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章标题</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token string\">'Status'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'STAT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 记录状态（Status），如 'PubMed-not-MEDLINE'，表示在 PubMed 中但未被 MEDLINE 索引</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token string\">'Last Revision Date'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 最后修订日期</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        <span class=\"token string\">'ISSN'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'IS'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 国际标准刊号</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token string\">'Type'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 提取文章类型</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        <span class=\"token string\">'Year of Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'DP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token string\">'DP'</span> <span class=\"token keyword\">in</span> record_efetch <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 出版年份</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        <span class=\"token string\">'Date of Electronic Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'DEP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 电子出版日期</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token string\">'Publication Date'</span><span class=\"token punctuation\">:</span> publication_date<span class=\"token punctuation\">,</span> <span class=\"token comment\"># 正式发表日期</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token string\">'Place of Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PL'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 出版地</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token string\">'F_Author'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'FAU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 作者全名</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        <span class=\"token string\">'Author'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 作者名字缩写</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        <span class=\"token string\">'Affiliation'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AD'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 机构信息</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token string\">'Abstract'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AB'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 摘要</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        <span class=\"token string\">'Language'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LA'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章语言</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token string\">'Keywords'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'OT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章关键词</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        <span class=\"token string\">'PMID'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># PubMed 文章 ID</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        <span class=\"token string\">'Medline Volume'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'VI'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># MEDLINE 卷号</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token string\">'Medline Issue'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'IP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># MEDLINE 期号</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token string\">'Medline Pagination'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PG'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># MEDLINE 页码</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        <span class=\"token string\">'DOI'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token string\">'LID'</span> <span class=\"token keyword\">in</span> record_efetch <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 数字对象标识符</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        <span class=\"token string\">'PMC'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMC'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># PubMed Central 文章 ID</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>        <span class=\"token string\">'Processing History'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PSTT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 处理历史</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        <span class=\"token string\">'Publication Status'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PST'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 出版状态</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        <span class=\"token string\">'Journal Title Abbreviation'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'TA'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 期刊缩写</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        <span class=\"token string\">'Journal Title'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'JT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 期刊全称</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        <span class=\"token string\">'Journal ID'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'JID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 期刊 ID</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        <span class=\"token string\">'Source'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'SO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章来源</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        <span class=\"token string\">'Grant List'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'GR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 资助号</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        <span class=\"token string\">'cited'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>linked<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 引用数量</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>        <span class=\"token string\">'cited_by'</span><span class=\"token punctuation\">:</span> linked<span class=\"token punctuation\">,</span> <span class=\"token comment\"># 引用该文章的 PubMed 文章 ID</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token string\">'References'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>references<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 参考文献数量</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        <span class=\"token string\">'References_PMID'</span><span class=\"token punctuation\">:</span> references<span class=\"token punctuation\">,</span> <span class=\"token comment\"># 参考文献的 PubMed 文章 ID</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h2 id=\"运行脚本\"><a class=\"anchor\" href=\"#运行脚本\">#</a> 运行脚本</h2>\n<p>在主程序中，我们定义检索词列表和对应的文件名列表，然后调用  <code>fetch_pubmed_data</code>  函数：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token comment\"># 单个检索词</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    term_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token triple-quoted-string string\">'''((ophthalmology[Text Word])) AND (ophthalmology[Title/Abstract])'''</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    fname_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'./ophthalmology.csv'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token comment\"># 多个检索词分别保存为多个文件</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token comment\"># term_list = ['''\"Refractive Errors\"[Text Word] AND \"Refractive Errors\"[Title/Abstract]''', </span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token comment\">#              '''\"diabetic retinopathy\"[Text Word] AND \"diabetic retinopathy\"[Title/Abstract]''', </span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token comment\">#              '''\"cornea diseases\" OR \"uveitis\" OR \"visual function\" OR \"ocular cancer\" OR \"choroidal diseases\" OR \"strabismus\"''']</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token comment\"># fname_list = ['./result/Eye_RE.csv', </span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token comment\">#               './result/Eye_DR.csv', </span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token comment\">#               './result/Eye_Other.csv']</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token keyword\">for</span> term<span class=\"token punctuation\">,</span> fname <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>term_list<span class=\"token punctuation\">,</span> fname_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        fetch_pubmed_data<span class=\"token punctuation\">(</span>term<span class=\"token punctuation\">,</span> fname<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>运行脚本后，符合条件的文献信息将被提取并保存到对应的 CSV 文件中。</p>\n<h2 id=\"完整代码\"><a class=\"anchor\" href=\"#完整代码\">#</a> 完整代码</h2>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> Bio <span class=\"token keyword\">import</span> Entrez<span class=\"token punctuation\">,</span> Medline</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> time</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> urllib<span class=\"token punctuation\">.</span>error <span class=\"token keyword\">import</span> HTTPError</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> ssl</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">import</span> urllib3</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># 禁用警告和证书验证</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>urllib3<span class=\"token punctuation\">.</span>disable_warnings<span class=\"token punctuation\">(</span>urllib3<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>InsecureRequestWarning<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>ssl<span class=\"token punctuation\">.</span>_create_default_https_context <span class=\"token operator\">=</span> ssl<span class=\"token punctuation\">.</span>_create_unverified_context</pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># 设置 NCBI 账户的邮箱</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>Entrez<span class=\"token punctuation\">.</span>email <span class=\"token operator\">=</span> <span class=\"token string\">\"your_email@example.com\"</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\"># 提取日期的正则表达式模式</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>date_pattern <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token string\">r'\\b\\d&#123;4&#125; \\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\b \\d&#123;1,2&#125;'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">fetch_pubmed_data</span><span class=\"token punctuation\">(</span>term<span class=\"token punctuation\">,</span> fname<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    从 PubMed 获取文献信息并保存到 CSV 文件。</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    参数:</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    - term: 检索词</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    - fname: 保存文件名</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>term<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    retmax <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"Count\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    pmid_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    <span class=\"token keyword\">if</span> retmax <span class=\"token operator\">&lt;</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>term<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span>retmax<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"IdList\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        start_year <span class=\"token operator\">=</span> <span class=\"token number\">2004</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        end_year <span class=\"token operator\">=</span> <span class=\"token number\">2024</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token keyword\">for</span> year <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>start_year<span class=\"token punctuation\">,</span> end_year <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>            subterm <span class=\"token operator\">=</span> term <span class=\"token operator\">+</span> <span class=\"token string-interpolation\"><span class=\"token string\">f' AND ((\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>year<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"[Date - Publication] : \"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>year<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"[Date - Publication]))'</span></span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>            handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>subterm<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>            record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>            handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>            retmax <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"Count\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>            handle_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>esearch<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> term<span class=\"token operator\">=</span>subterm<span class=\"token punctuation\">,</span> retmax<span class=\"token operator\">=</span>retmax<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>            record_esearch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_esearch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>            handle_esearch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>            pmid_list <span class=\"token operator\">+=</span> record_esearch<span class=\"token punctuation\">[</span><span class=\"token string\">\"IdList\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>        pmid_list <span class=\"token operator\">=</span> <span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>    data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>            <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>                handle_efetch <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>efetch<span class=\"token punctuation\">(</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span><span class=\"token operator\">=</span>pmid_list<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">:</span>i <span class=\"token operator\">+</span> <span class=\"token number\">50</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> rettype<span class=\"token operator\">=</span><span class=\"token string\">'medline'</span><span class=\"token punctuation\">,</span> retmode<span class=\"token operator\">=</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>                records_efetch <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>Medline<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>handle_efetch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>                handle_efetch<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>                <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>            <span class=\"token keyword\">except</span> HTTPError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>                <span class=\"token keyword\">if</span> e<span class=\"token punctuation\">.</span>code <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">429</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>                    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"efetch: HTTP错误 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">.</span>code<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">，5 秒后重试...\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>                    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>                    <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>                    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"efetch: HTTP错误: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>                    <span class=\"token keyword\">raise</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"efetch: Error: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>                time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>        <span class=\"token keyword\">for</span> record_efetch <span class=\"token keyword\">in</span> records_efetch<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>            PMID <span class=\"token operator\">=</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"82\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>            linked<span class=\"token punctuation\">,</span> references <span class=\"token operator\">=</span> fetch_citation_data<span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>            publication_date <span class=\"token operator\">=</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'SO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>            <span class=\"token keyword\">match</span> <span class=\"token operator\">=</span> date_pattern<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>publication_date<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>            formatted_publication_date <span class=\"token operator\">=</span> <span class=\"token keyword\">match</span><span class=\"token punctuation\">.</span>group<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> <span class=\"token keyword\">match</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>            record_dict <span class=\"token operator\">=</span> create_record_dict<span class=\"token punctuation\">(</span>record_efetch<span class=\"token punctuation\">,</span> formatted_publication_date<span class=\"token punctuation\">,</span> linked<span class=\"token punctuation\">,</span> references<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"90\"></td><td><pre>            data<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>record_dict<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre></pre></td></tr><tr><td data-num=\"92\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'已成功获取 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>pmid_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 篇文献信息'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>            df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>            df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>fname<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"95\"></td><td><pre></pre></td></tr><tr><td data-num=\"96\"></td><td><pre>        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre></pre></td></tr><tr><td data-num=\"98\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">fetch_citation_data</span><span class=\"token punctuation\">(</span>PMID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"99\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"100\"></td><td><pre>    获取引用和参考文献信息。</pre></td></tr><tr><td data-num=\"101\"></td><td><pre>    参数:</pre></td></tr><tr><td data-num=\"102\"></td><td><pre>    - PMID: PubMed 标识符</pre></td></tr><tr><td data-num=\"103\"></td><td><pre>    返回值:</pre></td></tr><tr><td data-num=\"104\"></td><td><pre>    - linked: 引用 PMID 列表</pre></td></tr><tr><td data-num=\"105\"></td><td><pre>    - references: 参考文献 PMID 列表</pre></td></tr><tr><td data-num=\"106\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>    linked <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>    references <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre></pre></td></tr><tr><td data-num=\"110\"></td><td><pre>    <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"112\"></td><td><pre>            handle_elink <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>elink<span class=\"token punctuation\">(</span>db<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span><span class=\"token operator\">=</span>PMID<span class=\"token punctuation\">,</span> linkname<span class=\"token operator\">=</span><span class=\"token string\">\"pubmed_pubmed_citedin,pubmed_pubmed_refs\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"113\"></td><td><pre>            record_elink <span class=\"token operator\">=</span> Entrez<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>handle_elink<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"114\"></td><td><pre>            handle_elink<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"115\"></td><td><pre>            <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"116\"></td><td><pre>        <span class=\"token keyword\">except</span> HTTPError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"117\"></td><td><pre>            <span class=\"token keyword\">if</span> e<span class=\"token punctuation\">.</span>code <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">429</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"118\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"elink: HTTP错误 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">.</span>code<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">，5 秒后重试...\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre>                time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>                <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre>            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"elink: HTTP错误: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"123\"></td><td><pre>                <span class=\"token keyword\">raise</span></pre></td></tr><tr><td data-num=\"124\"></td><td><pre>        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"elink: Error: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>e<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"126\"></td><td><pre>            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"127\"></td><td><pre>            <span class=\"token keyword\">continue</span></pre></td></tr><tr><td data-num=\"128\"></td><td><pre></pre></td></tr><tr><td data-num=\"129\"></td><td><pre>    <span class=\"token keyword\">if</span> record_elink <span class=\"token keyword\">and</span> <span class=\"token string\">\"LinkSetDb\"</span> <span class=\"token keyword\">in</span> record_elink<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"130\"></td><td><pre>        <span class=\"token keyword\">for</span> linkset <span class=\"token keyword\">in</span> record_elink<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkSetDb\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"131\"></td><td><pre>            <span class=\"token keyword\">if</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkName\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"pubmed_pubmed_citedin\"</span> <span class=\"token keyword\">and</span> <span class=\"token string\">\"Link\"</span> <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"132\"></td><td><pre>                linked<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">\"Id\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"Link\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"133\"></td><td><pre>            <span class=\"token keyword\">elif</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"LinkName\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"pubmed_pubmed_refs\"</span> <span class=\"token keyword\">and</span> <span class=\"token string\">\"Link\"</span> <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>                references<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">\"Id\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> linkset<span class=\"token punctuation\">[</span><span class=\"token string\">\"Link\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"135\"></td><td><pre></pre></td></tr><tr><td data-num=\"136\"></td><td><pre>    <span class=\"token keyword\">return</span> linked<span class=\"token punctuation\">,</span> references</pre></td></tr><tr><td data-num=\"137\"></td><td><pre></pre></td></tr><tr><td data-num=\"138\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">create_record_dict</span><span class=\"token punctuation\">(</span>record_efetch<span class=\"token punctuation\">,</span> publication_date<span class=\"token punctuation\">,</span> linked<span class=\"token punctuation\">,</span> references<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"139\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"140\"></td><td><pre>    创建记录字典。</pre></td></tr><tr><td data-num=\"141\"></td><td><pre>    参数:</pre></td></tr><tr><td data-num=\"142\"></td><td><pre>    - record_efetch: 文章记录</pre></td></tr><tr><td data-num=\"143\"></td><td><pre>    - publication_date: 正式发表日期</pre></td></tr><tr><td data-num=\"144\"></td><td><pre>    - linked: 引用 PMID 列表</pre></td></tr><tr><td data-num=\"145\"></td><td><pre>    - references: 参考文献 PMID 列表</pre></td></tr><tr><td data-num=\"146\"></td><td><pre>    返回值:</pre></td></tr><tr><td data-num=\"147\"></td><td><pre>    - record_dict: 记录字典</pre></td></tr><tr><td data-num=\"148\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"149\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"150\"></td><td><pre>        <span class=\"token string\">'Title'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'TI'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章标题</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>        <span class=\"token string\">'Status'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'STAT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 记录状态（Status），如 'PubMed-not-MEDLINE'，表示在 PubMed 中但未被 MEDLINE 索引</span></pre></td></tr><tr><td data-num=\"152\"></td><td><pre>        <span class=\"token string\">'Last Revision Date'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 最后修订日期</span></pre></td></tr><tr><td data-num=\"153\"></td><td><pre>        <span class=\"token string\">'ISSN'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'IS'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 国际标准刊号</span></pre></td></tr><tr><td data-num=\"154\"></td><td><pre>        <span class=\"token string\">'Type'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 提取文章类型</span></pre></td></tr><tr><td data-num=\"155\"></td><td><pre>        <span class=\"token string\">'Year of Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'DP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token string\">'DP'</span> <span class=\"token keyword\">in</span> record_efetch <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 出版年份</span></pre></td></tr><tr><td data-num=\"156\"></td><td><pre>        <span class=\"token string\">'Date of Electronic Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'DEP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 电子出版日期</span></pre></td></tr><tr><td data-num=\"157\"></td><td><pre>        <span class=\"token string\">'Publication Date'</span><span class=\"token punctuation\">:</span> publication_date<span class=\"token punctuation\">,</span> <span class=\"token comment\"># 正式发表日期</span></pre></td></tr><tr><td data-num=\"158\"></td><td><pre>        <span class=\"token string\">'Place of Publication'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PL'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 出版地</span></pre></td></tr><tr><td data-num=\"159\"></td><td><pre>        <span class=\"token string\">'F_Author'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'FAU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 作者全名</span></pre></td></tr><tr><td data-num=\"160\"></td><td><pre>        <span class=\"token string\">'Author'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 作者名字缩写</span></pre></td></tr><tr><td data-num=\"161\"></td><td><pre>        <span class=\"token string\">'Affiliation'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AD'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 机构信息</span></pre></td></tr><tr><td data-num=\"162\"></td><td><pre>        <span class=\"token string\">'Abstract'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'AB'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 摘要</span></pre></td></tr><tr><td data-num=\"163\"></td><td><pre>        <span class=\"token string\">'Language'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LA'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章语言</span></pre></td></tr><tr><td data-num=\"164\"></td><td><pre>        <span class=\"token string\">'Keywords'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'OT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章关键词</span></pre></td></tr><tr><td data-num=\"165\"></td><td><pre>        <span class=\"token string\">'PMID'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># PubMed 文章 ID</span></pre></td></tr><tr><td data-num=\"166\"></td><td><pre>        <span class=\"token string\">'Medline Volume'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'VI'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># MEDLINE 卷号</span></pre></td></tr><tr><td data-num=\"167\"></td><td><pre>        <span class=\"token string\">'Medline Issue'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'IP'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># MEDLINE 期号</span></pre></td></tr><tr><td data-num=\"168\"></td><td><pre>        <span class=\"token string\">'Medline Pagination'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PG'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># MEDLINE 页码</span></pre></td></tr><tr><td data-num=\"169\"></td><td><pre>        <span class=\"token string\">'DOI'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'LID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token string\">'LID'</span> <span class=\"token keyword\">in</span> record_efetch <span class=\"token keyword\">else</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 数字对象标识符</span></pre></td></tr><tr><td data-num=\"170\"></td><td><pre>        <span class=\"token string\">'PMC'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PMC'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># PubMed Central 文章 ID</span></pre></td></tr><tr><td data-num=\"171\"></td><td><pre>        <span class=\"token string\">'Processing History'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PSTT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 处理历史</span></pre></td></tr><tr><td data-num=\"172\"></td><td><pre>        <span class=\"token string\">'Publication Status'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'PST'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 出版状态</span></pre></td></tr><tr><td data-num=\"173\"></td><td><pre>        <span class=\"token string\">'Journal Title Abbreviation'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'TA'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 期刊缩写</span></pre></td></tr><tr><td data-num=\"174\"></td><td><pre>        <span class=\"token string\">'Journal Title'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'JT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 期刊全称</span></pre></td></tr><tr><td data-num=\"175\"></td><td><pre>        <span class=\"token string\">'Journal ID'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'JID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 期刊 ID</span></pre></td></tr><tr><td data-num=\"176\"></td><td><pre>        <span class=\"token string\">'Source'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'SO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 文章来源</span></pre></td></tr><tr><td data-num=\"177\"></td><td><pre>        <span class=\"token string\">'Grant List'</span><span class=\"token punctuation\">:</span> record_efetch<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'GR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'NA'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 资助号</span></pre></td></tr><tr><td data-num=\"178\"></td><td><pre>        <span class=\"token string\">'cited'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>linked<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 引用数量</span></pre></td></tr><tr><td data-num=\"179\"></td><td><pre>        <span class=\"token string\">'cited_by'</span><span class=\"token punctuation\">:</span> linked<span class=\"token punctuation\">,</span> <span class=\"token comment\"># 引用该文章的 PubMed 文章 ID</span></pre></td></tr><tr><td data-num=\"180\"></td><td><pre>        <span class=\"token string\">'References'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>references<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 参考文献数量</span></pre></td></tr><tr><td data-num=\"181\"></td><td><pre>        <span class=\"token string\">'References_PMID'</span><span class=\"token punctuation\">:</span> references<span class=\"token punctuation\">,</span> <span class=\"token comment\"># 参考文献的 PubMed 文章 ID</span></pre></td></tr><tr><td data-num=\"182\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"183\"></td><td><pre></pre></td></tr><tr><td data-num=\"184\"></td><td><pre><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"185\"></td><td><pre>    <span class=\"token comment\"># 单个检索词</span></pre></td></tr><tr><td data-num=\"186\"></td><td><pre>    term_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token triple-quoted-string string\">'''((ophthalmology[Text Word])) AND (ophthalmology[Title/Abstract])'''</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"187\"></td><td><pre>    fname_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'./ophthalmology.csv'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"188\"></td><td><pre></pre></td></tr><tr><td data-num=\"189\"></td><td><pre>    <span class=\"token comment\"># 多个检索词分别保存为多个文件</span></pre></td></tr><tr><td data-num=\"190\"></td><td><pre>    <span class=\"token comment\"># term_list = ['''\"Refractive Errors\"[Text Word] AND \"Refractive Errors\"[Title/Abstract]''', </span></pre></td></tr><tr><td data-num=\"191\"></td><td><pre>    <span class=\"token comment\">#              '''\"diabetic retinopathy\"[Text Word] AND \"diabetic retinopathy\"[Title/Abstract]''', </span></pre></td></tr><tr><td data-num=\"192\"></td><td><pre>    <span class=\"token comment\">#              '''\"cornea diseases\" OR \"uveitis\" OR \"visual function\" OR \"ocular cancer\" OR \"choroidal diseases\" OR \"strabismus\"''']</span></pre></td></tr><tr><td data-num=\"193\"></td><td><pre></pre></td></tr><tr><td data-num=\"194\"></td><td><pre>    <span class=\"token comment\"># fname_list = ['./result/Eye_RE.csv', </span></pre></td></tr><tr><td data-num=\"195\"></td><td><pre>    <span class=\"token comment\">#               './result/Eye_DR.csv', </span></pre></td></tr><tr><td data-num=\"196\"></td><td><pre>    <span class=\"token comment\">#               './result/Eye_Other.csv']</span></pre></td></tr><tr><td data-num=\"197\"></td><td><pre></pre></td></tr><tr><td data-num=\"198\"></td><td><pre></pre></td></tr><tr><td data-num=\"199\"></td><td><pre>    <span class=\"token keyword\">for</span> term<span class=\"token punctuation\">,</span> fname <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>term_list<span class=\"token punctuation\">,</span> fname_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"200\"></td><td><pre>        fetch_pubmed_data<span class=\"token punctuation\">(</span>term<span class=\"token punctuation\">,</span> fname<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h2 id=\"参考\"><a class=\"anchor\" href=\"#参考\">#</a> 参考</h2>\n<ul>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/books/NBK25501/\">Entrez Programming Utilities Help</a></li>\n<li><a href=\"https://whylim.github.io/E-utilities_zh-CN/\">我的汉化文档</a></li>\n</ul>\n",
            "tags": [
                "Python",
                "Entrez API",
                "NCBI"
            ]
        },
        {
            "id": "https://new.limina.top/2020/11/01/jupyternotebook%E5%8C%85%E5%AF%BC%E5%85%A5%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/",
            "url": "https://new.limina.top/2020/11/01/jupyternotebook%E5%8C%85%E5%AF%BC%E5%85%A5%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/",
            "title": "jupyter notebook 包导入路径问题",
            "date_published": "2020-11-01T02:04:00.000Z",
            "content_html": "<blockquote>\n<p>之前在 windows 下自己写的 python 包只要放到  <code>.../anaconda3/lib/pythonx.x/site-packages</code>  下就能导入了，到 ubuntu 里发现不行，因为由于各种奇奇怪怪的原因电脑上装了两个 jupyter notebook… 而且路径都不对</p>\n<p>感谢 CSDN 的大哥，让我用上了更简单的 Ubuntu</p>\n<p>参考：<a href=\"https://blog.csdn.net/qq%5C_34650787/article/details/83304080\">https://blog.csdn.net/qq\\_34650787/article/details/83304080</a></p>\n</blockquote>\n<p>先去两个 jupyter notebook 里 import 一个包  <code>sys</code></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>sys<span class=\"token punctuation\">.</span>executable</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 一个返回 '/usr/bin/python3'   这个是 anaconda 自带的 jupyter</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># 一个返回 '/snap/jupyter/6/bin/python'   这是我后来重装的 jupyter</span></pre></td></tr></table></figure><p>可能 anaconda 没装好</p>\n<p>终端输入 python3</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>limin@limin-Lenovo-XiaoXin-Air-15IKBR:~$ python3</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Python <span class=\"token number\">3.8</span>.5 <span class=\"token punctuation\">(</span>default, Jul <span class=\"token number\">28</span> <span class=\"token number\">2020</span>, <span class=\"token number\">12</span>:59:40<span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>GCC <span class=\"token number\">9.3</span>.0<span class=\"token punctuation\">]</span> on linux</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Type <span class=\"token string\">\"help\"</span>, <span class=\"token string\">\"copyright\"</span>, <span class=\"token string\">\"credits\"</span> or <span class=\"token string\">\"license\"</span> <span class=\"token keyword\">for</span> <span class=\"token function\">more</span> information.</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span></pre></td></tr></table></figure><p>没有 anaconda</p>\n<p>去添加一下环境变量</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>gedit ~/.bashrc</pre></td></tr></table></figure><p>在最后一行加入</p>\n<pre><code>export PATH=$PATH:/home/limin/anaconda3/bin\n</code></pre>\n<p>回到 shell，source 一下</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">source</span> ~/.bashrc</pre></td></tr></table></figure><p>再输入 python3（ubuntu20.04 内置了 python3，所以输 python 也行）</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>limin@limin-Lenovo-XiaoXin-Air-15IKBR:~$ python</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Python <span class=\"token number\">3.8</span>.3 <span class=\"token punctuation\">(</span>default, Jul  <span class=\"token number\">2</span> <span class=\"token number\">2020</span>, <span class=\"token number\">16</span>:21:59<span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>GCC <span class=\"token number\">7.3</span>.0<span class=\"token punctuation\">]</span> :: Anaconda, Inc. on linux</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>Type <span class=\"token string\">\"help\"</span>, <span class=\"token string\">\"copyright\"</span>, <span class=\"token string\">\"credits\"</span> or <span class=\"token string\">\"license\"</span> <span class=\"token keyword\">for</span> <span class=\"token function\">more</span> information.</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token operator\">>></span><span class=\"token operator\">></span></pre></td></tr></table></figure><p>anaconda 出来了</p>\n<p>import 一下  <code>sys</code></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>sys<span class=\"token punctuation\">.</span>executable</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 返回 '/home/limin/anaconda3/bin/python'</span></pre></td></tr></table></figure><p>去 jupyter notebook 里 import</p>\n<p>第一个返回  <code>'/home/limin/anaconda3/bin/python'</code></p>\n<p>第二个仍然返回  <code>'/snap/jupyter/6/bin/python'</code></p>\n<p>所以用第一个</p>\n<p>把写的包放到  <code>/home/limin/anaconda3/lib/python3.8/site-packages</code></p>\n<p>再 import 就没问题了</p>\n<h2 id=\"后续新问题\"><a class=\"anchor\" href=\"#后续新问题\">#</a> 后续新问题</h2>\n<p>没有在 conda 环境里进入 jupyter 的话，路径就是自带 python 的包路径了</p>\n<p>conda activate 再 jupyter notebook 就行</p>\n",
            "tags": [
                "Python"
            ]
        }
    ]
}